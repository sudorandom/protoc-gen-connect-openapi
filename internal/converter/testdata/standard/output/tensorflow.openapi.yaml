openapi: 3.1.0
info:
  title: tensorflowtest
paths:
  /tensorflowtest.MasterService/CreateSession:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: CreateSession
      description: Creates a session.
      operationId: tensorflowtest.MasterService.CreateSession
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.CreateSessionRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.CreateSessionResponse'
  /tensorflowtest.MasterService/ExtendSession:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: ExtendSession
      description: Extends a session.
      operationId: tensorflowtest.MasterService.ExtendSession
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.ExtendSessionRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.ExtendSessionResponse'
  /tensorflowtest.MasterService/PartialRunSetup:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: PartialRunSetup
      description: Prepares future partial run calls.
      operationId: tensorflowtest.MasterService.PartialRunSetup
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.PartialRunSetupRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.PartialRunSetupResponse'
  /tensorflowtest.MasterService/RunStep:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: RunStep
      description: Drives the graph computation.
      operationId: tensorflowtest.MasterService.RunStep
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.RunStepRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.RunStepResponse'
  /tensorflowtest.MasterService/CloseSession:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: CloseSession
      description: Closes a session.
      operationId: tensorflowtest.MasterService.CloseSession
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.CloseSessionRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.CloseSessionResponse'
  /tensorflowtest.MasterService/ListDevices:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: ListDevices
      description: List the devices usable by the master.
      operationId: tensorflowtest.MasterService.ListDevices
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.ListDevicesRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.ListDevicesResponse'
  /tensorflowtest.MasterService/Reset:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: Reset
      description: |-
        Close and abandon all existing sessions.  Ongoing computations
         will no longer affect fresh ones via the resources in containers listed in
         the ResetRequest.  See ResetRequest for more details.
      operationId: tensorflowtest.MasterService.Reset
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.ResetRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.ResetResponse'
  /tensorflowtest.MasterService/MakeCallable:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: MakeCallable
      description: Registers a callable for execution with RunCallable.
      operationId: tensorflowtest.MasterService.MakeCallable
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.MakeCallableRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.MakeCallableResponse'
  /tensorflowtest.MasterService/RunCallable:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: RunCallable
      description: Executes a callable registered with MakeCallable.
      operationId: tensorflowtest.MasterService.RunCallable
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.RunCallableRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.RunCallableResponse'
  /tensorflowtest.MasterService/ReleaseCallable:
    post:
      tags:
        - tensorflowtest.MasterService
      summary: ReleaseCallable
      description: Frees resources associated with a callable registered with MakeCallable.
      operationId: tensorflowtest.MasterService.ReleaseCallable
      parameters:
        - name: Connect-Protocol-Version
          in: header
          required: true
          schema:
            $ref: '#/components/schemas/connect-protocol-version'
        - name: Connect-Timeout-Ms
          in: header
          schema:
            $ref: '#/components/schemas/connect-timeout-header'
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/tensorflow.ReleaseCallableRequest'
        required: true
      responses:
        default:
          description: Error
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/connect.error'
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/tensorflow.ReleaseCallableResponse'
components:
  schemas:
    tensorflow.ConfigProto.Experimental.MlirBridgeRollout:
      type: string
      title: MlirBridgeRollout
      enum:
        - MLIR_BRIDGE_ROLLOUT_UNSPECIFIED
        - MLIR_BRIDGE_ROLLOUT_ENABLED
        - MLIR_BRIDGE_ROLLOUT_DISABLED
      description: An enum that describes the state of the MLIR bridge rollout.
    tensorflow.DataType:
      type: string
      title: DataType
      enum:
        - DT_INVALID
        - DT_FLOAT
        - DT_DOUBLE
        - DT_INT32
        - DT_UINT8
        - DT_INT16
        - DT_INT8
        - DT_STRING
        - DT_COMPLEX64
        - DT_INT64
        - DT_BOOL
        - DT_QINT8
        - DT_QUINT8
        - DT_QINT32
        - DT_BFLOAT16
        - DT_QINT16
        - DT_QUINT16
        - DT_UINT16
        - DT_COMPLEX128
        - DT_HALF
        - DT_RESOURCE
        - DT_VARIANT
        - DT_UINT32
        - DT_UINT64
        - DT_FLOAT8_E5M2
        - DT_FLOAT8_E4M3FN
        - DT_FLOAT_REF
        - DT_DOUBLE_REF
        - DT_INT32_REF
        - DT_UINT8_REF
        - DT_INT16_REF
        - DT_INT8_REF
        - DT_STRING_REF
        - DT_COMPLEX64_REF
        - DT_INT64_REF
        - DT_BOOL_REF
        - DT_QINT8_REF
        - DT_QUINT8_REF
        - DT_QINT32_REF
        - DT_BFLOAT16_REF
        - DT_QINT16_REF
        - DT_QUINT16_REF
        - DT_UINT16_REF
        - DT_COMPLEX128_REF
        - DT_HALF_REF
        - DT_RESOURCE_REF
        - DT_VARIANT_REF
        - DT_UINT32_REF
        - DT_UINT64_REF
        - DT_FLOAT8_E5M2_REF
        - DT_FLOAT8_E4M3FN_REF
      description: |-
        (== suppress_warning documentation-presence ==)
         LINT.IfChange
    tensorflow.FullTypeId:
      type: string
      title: FullTypeId
      enum:
        - TFT_UNSET
        - TFT_VAR
        - TFT_ANY
        - TFT_PRODUCT
        - TFT_NAMED
        - TFT_FOR_EACH
        - TFT_CALLABLE
        - TFT_TENSOR
        - TFT_ARRAY
        - TFT_OPTIONAL
        - TFT_LITERAL
        - TFT_ENCODED
        - TFT_SHAPE_TENSOR
        - TFT_BOOL
        - TFT_UINT8
        - TFT_UINT16
        - TFT_UINT32
        - TFT_UINT64
        - TFT_INT8
        - TFT_INT16
        - TFT_INT32
        - TFT_INT64
        - TFT_HALF
        - TFT_FLOAT
        - TFT_DOUBLE
        - TFT_BFLOAT16
        - TFT_COMPLEX64
        - TFT_COMPLEX128
        - TFT_STRING
        - TFT_DATASET
        - TFT_RAGGED
        - TFT_ITERATOR
        - TFT_MUTEX_LOCK
        - TFT_LEGACY_VARIANT
      description: |-
        LINT.IfChange
         Experimental. Represents the complete type information of a TensorFlow value.
    tensorflow.OptimizerOptions.GlobalJitLevel:
      type: string
      title: GlobalJitLevel
      enum:
        - DEFAULT
        - OFF
        - ON_1
        - ON_2
      description: Control the use of the compiler/jit.  Experimental.
    tensorflow.OptimizerOptions.Level:
      type: string
      title: Level
      enum:
        - L1
        - L0
      description: Optimization level
    tensorflow.RewriterConfig.CpuLayout:
      type: string
      title: CpuLayout
      enum:
        - NO_CONVERSION_ON_CPU
        - NCHW_TO_NHWC
        - NHWC_TO_NCHW
      description: Enum for layout conversion between NCHW and NHWC on CPU. Default is OFF.
    tensorflow.RewriterConfig.MemOptType:
      type: string
      title: MemOptType
      enum:
        - DEFAULT_MEM_OPT
        - NO_MEM_OPT
        - MANUAL
        - SWAPPING_HEURISTICS
        - RECOMPUTATION_HEURISTICS
        - SCHEDULING_HEURISTICS
        - HEURISTICS
    tensorflow.RewriterConfig.NumIterationsType:
      type: string
      title: NumIterationsType
      enum:
        - DEFAULT_NUM_ITERS
        - ONE
        - TWO
      description: |-
        Enum controlling the number of times to run optimizers. The default is to
         run them twice.
    tensorflow.RewriterConfig.Toggle:
      type: string
      title: Toggle
      enum:
        - DEFAULT
        - ON
        - OFF
        - AGGRESSIVE
        - EXPERIMENTAL_MLIR
        - EXPERIMENTAL_BOTH
    tensorflow.RunOptions.TraceLevel:
      type: string
      title: TraceLevel
      enum:
        - NO_TRACE
        - SOFTWARE_TRACE
        - HARDWARE_TRACE
        - FULL_TRACE
      description: |-
        TODO(pbar) Turn this into a TraceOptions proto which allows
         tracing to be controlled in a more orthogonal manner?
    tensorflow.VerifierConfig.Toggle:
      type: string
      title: Toggle
      enum:
        - DEFAULT
        - ON
        - OFF
    tensorflow.error.Code:
      type: string
      title: Code
      enum:
        - OK
        - CANCELLED
        - UNKNOWN
        - INVALID_ARGUMENT
        - DEADLINE_EXCEEDED
        - NOT_FOUND
        - ALREADY_EXISTS
        - PERMISSION_DENIED
        - UNAUTHENTICATED
        - RESOURCE_EXHAUSTED
        - FAILED_PRECONDITION
        - ABORTED
        - OUT_OF_RANGE
        - UNIMPLEMENTED
        - INTERNAL
        - UNAVAILABLE
        - DATA_LOSS
        - DO_NOT_USE_RESERVED_FOR_FUTURE_EXPANSION_USE_DEFAULT_IN_SWITCH_INSTEAD_
      description: |-
        The canonical error codes for TensorFlow APIs.

         Warnings:

         -   Do not change any numeric assignments.
         -   Changes to this list should only be made if there is a compelling
             need that can't be satisfied in another way.  Such changes
             must be approved by at least two OWNERS.
         -   These error codes must match gRPC and protobuf error codes (except for
             DO_NOT_USE_RESERVED_FOR_FUTURE_EXPANSION_USE_DEFAULT_IN_SWITCH_INSTEAD_).

         Sometimes multiple error codes may apply.  Services should return
         the most specific error code that applies.  For example, prefer
         OUT_OF_RANGE over FAILED_PRECONDITION if both codes apply.
         Similarly prefer NOT_FOUND or ALREADY_EXISTS over FAILED_PRECONDITION.
    tensorflow.AllocationDescription:
      type: object
      properties:
        requestedBytes:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: requested_bytes
          description: Total number of bytes requested
        allocatedBytes:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: allocated_bytes
          description: Total number of bytes allocated if known
        allocatorName:
          type: string
          title: allocator_name
          description: Name of the allocator used
        allocationId:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: allocation_id
          description: Identifier of the allocated buffer if known
        hasSingleReference:
          type: boolean
          title: has_single_reference
          description: Set if this tensor only has one remaining reference
        ptr:
          oneOf:
            - type: string
            - type: integer
          title: ptr
          description: Address of the allocation.
      title: AllocationDescription
      additionalProperties: false
    tensorflow.AllocationRecord:
      type: object
      properties:
        allocMicros:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: alloc_micros
          description: The timestamp of the operation.
        allocBytes:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: alloc_bytes
          description: Number of bytes allocated, or de-allocated if negative.
      title: AllocationRecord
      additionalProperties: false
      description: An allocation/de-allocation operation performed by the allocator.
    tensorflow.AllocatorMemoryUsed:
      type: object
      properties:
        allocatorName:
          type: string
          title: allocator_name
        totalBytes:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: total_bytes
          description: These are per-node allocator memory stats.
        peakBytes:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: peak_bytes
        liveBytes:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: live_bytes
          description: The bytes that are not deallocated.
        allocationRecords:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.AllocationRecord'
          title: allocation_records
          description: The allocation and deallocation timeline.
        allocatorBytesInUse:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: allocator_bytes_in_use
          description: |-
            These are snapshots of the overall allocator memory stats.
             The number of live bytes currently allocated by the allocator.
      title: AllocatorMemoryUsed
      additionalProperties: false
    tensorflow.AttrValue:
      type: object
      allOf:
        - anyOf:
            - required:
                - b
            - required:
                - f
            - required:
                - func
            - required:
                - i
            - required:
                - list
            - required:
                - placeholder
            - required:
                - s
            - required:
                - shape
            - required:
                - tensor
            - required:
                - type
            - not:
                anyOf:
                  - required:
                      - b
                  - required:
                      - f
                  - required:
                      - func
                  - required:
                      - i
                  - required:
                      - list
                  - required:
                      - placeholder
                  - required:
                      - s
                  - required:
                      - shape
                  - required:
                      - tensor
                  - required:
                      - type
      anyOf:
        - required:
            - b
        - required:
            - f
        - required:
            - func
        - required:
            - i
        - required:
            - list
        - required:
            - placeholder
        - required:
            - s
        - required:
            - shape
        - required:
            - tensor
        - required:
            - type
        - not:
            anyOf:
              - required:
                  - b
              - required:
                  - f
              - required:
                  - func
              - required:
                  - i
              - required:
                  - list
              - required:
                  - placeholder
              - required:
                  - s
              - required:
                  - shape
              - required:
                  - tensor
              - required:
                  - type
      properties:
        s:
          type: string
          title: s
          format: byte
          description: '"string"'
        i:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: i
          description: '"int"'
        f:
          type: number
          title: f
          format: float
          description: '"float"'
        b:
          type: boolean
          title: b
          description: '"bool"'
        type:
          allOf:
            - title: type
              description: '"type"'
            - $ref: '#/components/schemas/tensorflow.DataType'
        shape:
          allOf:
            - title: shape
              description: '"shape"'
            - $ref: '#/components/schemas/tensorflow.TensorShapeProto'
        tensor:
          allOf:
            - title: tensor
              description: '"tensor"'
            - $ref: '#/components/schemas/tensorflow.TensorProto'
        list:
          allOf:
            - title: list
              description: any "list(...)"
            - $ref: '#/components/schemas/tensorflow.AttrValue.ListValue'
        func:
          allOf:
            - title: func
              description: |-
                "func" represents a function. func.name is a function's name or
                 a primitive op's name. func.attr.first is the name of an attr
                 defined for that function. func.attr.second is the value for
                 that attr in the instantiation.
            - $ref: '#/components/schemas/tensorflow.NameAttrList'
        placeholder:
          type: string
          title: placeholder
          description: |-
            This is a placeholder only used in nodes defined inside a
             function.  It indicates the attr value will be supplied when
             the function is instantiated.  For example, let us suppose a
             node "N" in function "FN". "N" has an attr "A" with value
             placeholder = "foo". When FN is instantiated with attr "foo"
             set to "bar", the instantiated node N's attr A will have been
             given the value "bar".
      title: AttrValue
      additionalProperties: false
      description: |-
        Protocol buffer representing the value for an attr used to configure an Op.
         Comment indicates the corresponding attr type.  Only the field matching the
         attr type may be filled.
    tensorflow.AttrValue.ListValue:
      type: object
      properties:
        s:
          type: array
          items:
            type: string
            format: byte
          title: s
          description: '"list(string)"'
        i:
          type: array
          items:
            oneOf:
              - type: string
              - type: integer
                format: int64
          title: i
          description: '"list(int)"'
        f:
          type: array
          items:
            type: number
            format: float
          title: f
          description: '"list(float)"'
        b:
          type: array
          items:
            type: boolean
          title: b
          description: '"list(bool)"'
        type:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.DataType'
          title: type
          description: '"list(type)"'
        shape:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.TensorShapeProto'
          title: shape
          description: '"list(shape)"'
        tensor:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.TensorProto'
          title: tensor
          description: '"list(tensor)"'
        func:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.NameAttrList'
          title: func
          description: '"list(attr)"'
      title: ListValue
      additionalProperties: false
      description: LINT.IfChange
    tensorflow.AutoParallelOptions:
      type: object
      properties:
        enable:
          type: boolean
          title: enable
        numReplicas:
          type: integer
          title: num_replicas
          format: int32
      title: AutoParallelOptions
      additionalProperties: false
    tensorflow.CallableOptions:
      type: object
      properties:
        feed:
          type: array
          items:
            type: string
          title: feed
          description: Tensors to be fed in the callable. Each feed is the name of a tensor.
        fetch:
          type: array
          items:
            type: string
          title: fetch
          description: |-
            Fetches. A list of tensor names. The caller of the callable expects a
             tensor to be returned for each fetch[i] (see RunStepResponse.tensor). The
             order of specified fetches does not change the execution order.
        target:
          type: array
          items:
            type: string
          title: target
          description: |-
            Target Nodes. A list of node names. The named nodes will be run by the
             callable but their outputs will not be returned.
        runOptions:
          allOf:
            - title: run_options
              description: Options that will be applied to each run.
            - $ref: '#/components/schemas/tensorflow.RunOptions'
        tensorConnection:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.TensorConnection'
          title: tensor_connection
          description: |-
            Tensors to be connected in the callable. Each TensorConnection denotes
             a pair of tensors in the graph, between which an edge will be created
             in the callable.
        feedDevices:
          type: object
          title: feed_devices
          additionalProperties:
            type: string
            title: value
          description: |-
            The Tensor objects fed in the callable and fetched from the callable
             are expected to be backed by host (CPU) memory by default.

             The options below allow changing that - feeding tensors backed by
             device memory, or returning tensors that are backed by device memory.

             The maps below map the name of a feed/fetch tensor (which appears in
             'feed' or 'fetch' fields above), to the fully qualified name of the device
             owning the memory backing the contents of the tensor.

             For example, creating a callable with the following options:

             CallableOptions {
               feed: "a:0"
               feed: "b:0"

               fetch: "x:0"
               fetch: "y:0"

               feed_devices: {
                 "a:0": "/job:localhost/replica:0/task:0/device:GPU:0"
               }

               fetch_devices: {
                 "y:0": "/job:localhost/replica:0/task:0/device:GPU:0"
              }
             }

             means that the Callable expects:
             - The first argument ("a:0") is a Tensor backed by GPU memory.
             - The second argument ("b:0") is a Tensor backed by host memory.
             and of its return values:
             - The first output ("x:0") will be backed by host memory.
             - The second output ("y:0") will be backed by GPU memory.

             FEEDS:
             It is the responsibility of the caller to ensure that the memory of the fed
             tensors will be correctly initialized and synchronized before it is
             accessed by operations executed during the call to Session::RunCallable().

             This is typically ensured by using the TensorFlow memory allocators
             (Device::GetAllocator()) to create the Tensor to be fed.

             Alternatively, for CUDA-enabled GPU devices, this typically means that the
             operation that produced the contents of the tensor has completed, i.e., the
             CUDA stream has been synchronized (e.g., via cuCtxSynchronize() or
             cuStreamSynchronize()).
        fetchDevices:
          type: object
          title: fetch_devices
          additionalProperties:
            type: string
            title: value
        fetchSkipSync:
          type: boolean
          title: fetch_skip_sync
          description: |-
            By default, RunCallable() will synchronize the GPU stream before returning
             fetched tensors on a GPU device, to ensure that the values in those tensors
             have been produced. This simplifies interacting with the tensors, but
             potentially incurs a performance hit.

             If this options is set to true, the caller is responsible for ensuring
             that the values in the fetched tensors have been produced before they are
             used. The caller can do this by invoking `Device::Sync()` on the underlying
             device(s), or by feeding the tensors back to the same Session using
             `feed_devices` with the same corresponding device name.
      title: CallableOptions
      additionalProperties: false
      description: |-
        Defines a subgraph in another `GraphDef` as a set of feed points and nodes
         to be fetched or executed.

         Compare with the arguments to `Session::Run()`.
    tensorflow.CallableOptions.FeedDevicesEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          type: string
          title: value
      title: FeedDevicesEntry
      additionalProperties: false
    tensorflow.CallableOptions.FetchDevicesEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          type: string
          title: value
      title: FetchDevicesEntry
      additionalProperties: false
    tensorflow.CloseSessionRequest:
      type: object
      properties:
        sessionHandle:
          type: string
          title: session_handle
          description: |-
            REQUIRED: session_handle must be returned by a CreateSession call
             to the same master service.
      title: CloseSessionRequest
      additionalProperties: false
    tensorflow.CloseSessionResponse:
      type: object
      title: CloseSessionResponse
      additionalProperties: false
    tensorflow.ClusterDef:
      type: object
      properties:
        job:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.JobDef'
          title: job
          description: The jobs that comprise the cluster.
      title: ClusterDef
      additionalProperties: false
      description: Defines a TensorFlow cluster as a set of jobs.
    tensorflow.ConfigProto:
      type: object
      properties:
        deviceCount:
          type: object
          title: device_count
          additionalProperties:
            type: integer
            title: value
            format: int32
          description: |-
            Map from device type name (e.g., "CPU" or "GPU" ) to maximum
             number of devices of that type to use.  If a particular device
             type is not found in the map, the system picks an appropriate
             number.
        intraOpParallelismThreads:
          type: integer
          title: intra_op_parallelism_threads
          format: int32
          description: |-
            The execution of an individual op (for some op types) can be
             parallelized on a pool of intra_op_parallelism_threads.
             0 means the system picks an appropriate number.

             If you create an ordinary session, e.g., from Python or C++,
             then there is exactly one intra op thread pool per process.
             The first session created determines the number of threads in this pool.
             All subsequent sessions reuse/share this one global pool.

             There are notable exceptions to the default behavior described above:
             1. There is an environment variable  for overriding this thread pool,
                named TF_OVERRIDE_GLOBAL_THREADPOOL.
             2. When connecting to a server, such as a remote `tf.train.Server`
                instance, then this option will be ignored altogether.
        interOpParallelismThreads:
          type: integer
          title: inter_op_parallelism_threads
          format: int32
          description: |-
            Nodes that perform blocking operations are enqueued on a pool of
             inter_op_parallelism_threads available in each process.

             0 means the system picks an appropriate number.
             Negative means all operations are performed in caller's thread.

             Note that the first Session created in the process sets the
             number of threads for all future sessions unless use_per_session_threads is
             true or session_inter_op_thread_pool is configured.
        usePerSessionThreads:
          type: boolean
          title: use_per_session_threads
          description: |-
            If true, use a new set of threads for this session rather than the global
             pool of threads. Only supported by direct sessions.

             If false, use the global threads created by the first session, or the
             per-session thread pools configured by session_inter_op_thread_pool.

             This option is deprecated. The same effect can be achieved by setting
             session_inter_op_thread_pool to have one element, whose num_threads equals
             inter_op_parallelism_threads.
        sessionInterOpThreadPool:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.ThreadPoolOptionProto'
          title: session_inter_op_thread_pool
          description: |-
            This option is experimental - it may be replaced with a different mechanism
             in the future.

             Configures session thread pools. If this is configured, then RunOptions for
             a Run call can select the thread pool to use.

             The intended use is for when some session invocations need to run in a
             background pool limited to a small number of threads:
             - For example, a session may be configured to have one large pool (for
             regular compute) and one small pool (for periodic, low priority work);
             using the small pool is currently the mechanism for limiting the inter-op
             parallelism of the low priority work.  Note that it does not limit the
             parallelism of work spawned by a single op kernel implementation.
             - Using this setting is normally not needed in training, but may help some
             serving use cases.
             - It is also generally recommended to set the global_name field of this
             proto, to avoid creating multiple large pools. It is typically better to
             run the non-low-priority work, even across sessions, in a single large
             pool.
        placementPeriod:
          type: integer
          title: placement_period
          format: int32
          description: |-
            Assignment of Nodes to Devices is recomputed every placement_period
             steps until the system warms up (at which point the recomputation
             typically slows down automatically).
        deviceFilters:
          type: array
          items:
            type: string
          title: device_filters
          description: |-
            When any filters are present sessions will ignore all devices which do not
             match the filters. Each filter can be partially specified, e.g. "/job:ps"
             "/job:worker/replica:3", etc.
        gpuOptions:
          allOf:
            - title: gpu_options
              description: Options that apply to all GPUs.
            - $ref: '#/components/schemas/tensorflow.GPUOptions'
        allowSoftPlacement:
          type: boolean
          title: allow_soft_placement
          description: |-
            Whether soft placement is allowed. If allow_soft_placement is true,
             an op will be placed on CPU if
               1. there's no GPU implementation for the OP
             or
               2. no GPU devices are known or registered
             or
               3. need to co-locate with reftype input(s) which are from CPU.
        logDevicePlacement:
          type: boolean
          title: log_device_placement
          description: Whether device placements should be logged.
        graphOptions:
          allOf:
            - title: graph_options
              description: Options that apply to all graphs.
            - $ref: '#/components/schemas/tensorflow.GraphOptions'
        operationTimeoutInMs:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: operation_timeout_in_ms
          description: |-
            Global timeout for all blocking operations in this session.  If non-zero,
             and not overridden on a per-operation basis, this value will be used as the
             deadline for all blocking operations.
        rpcOptions:
          allOf:
            - title: rpc_options
              description: Options that apply when this session uses the distributed runtime.
            - $ref: '#/components/schemas/tensorflow.RPCOptions'
        clusterDef:
          allOf:
            - title: cluster_def
              description: Optional list of all workers to use in this session.
            - $ref: '#/components/schemas/tensorflow.ClusterDef'
        isolateSessionState:
          type: boolean
          title: isolate_session_state
          description: |-
            If true, any resources such as Variables used in the session will not be
             shared with other sessions. However, when clusterspec propagation is
             enabled, this field is ignored and sessions are always isolated.
        shareClusterDevicesInSession:
          type: boolean
          title: share_cluster_devices_in_session
          description: |-
            When true, WorkerSessions are created with device attributes from the
             full cluster.
             This is helpful when a worker wants to partition a graph
             (for example during a PartitionedCallOp).
        experimental:
          allOf:
            - title: experimental
            - $ref: '#/components/schemas/tensorflow.ConfigProto.Experimental'
      title: ConfigProto
      additionalProperties: false
      description: |-
        Session configuration parameters.
         The system picks appropriate values for fields that are not set.
    tensorflow.ConfigProto.DeviceCountEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          type: integer
          title: value
          format: int32
      title: DeviceCountEntry
      additionalProperties: false
    tensorflow.ConfigProto.Experimental:
      type: object
      properties:
        collectiveGroupLeader:
          type: string
          title: collective_group_leader
          description: Task name for group resolution.
        executorType:
          type: string
          title: executor_type
          description: |-
            Which executor to use, the default executor will be used
             if it is an empty string or "DEFAULT"
        recvBufMaxChunk:
          type: integer
          title: recv_buf_max_chunk
          format: int32
          description: |-
            Guidance to formatting of large RecvBuf fields for transfer.
             Any positive value sets the max chunk size.  0 defaults to 4096.
             Any negative value indicates no max, i.e. one chunk only.
        useNumaAffinity:
          type: boolean
          title: use_numa_affinity
          description: |-
            If true, and supported by the platform, the runtime will attempt to
             use NUMA affinity where applicable.  One consequence will be the
             existence of as many CPU devices as there are available NUMA nodes.
        collectiveDeterministicSequentialExecution:
          type: boolean
          title: collective_deterministic_sequential_execution
          description: |-
            If true, make collective op execution order sequential and deterministic
             for potentially concurrent collective instances.
        collectiveNccl:
          type: boolean
          title: collective_nccl
          description: |-
            If true, use NCCL for CollectiveOps.  This feature is highly
             experimental.
        shareSessionStateInClusterspecPropagation:
          type: boolean
          title: share_session_state_in_clusterspec_propagation
          description: |-
            In the following, session state means the value of a variable, elements
             in a hash table, or any other resource, accessible by worker sessions
             held by a TF server.

             When ClusterSpec propagation is enabled, the value of
             isolate_session_state is ignored when deciding whether to share session
             states in a TF server (for backwards compatibility reasons).
             - If share_session_state_in_clusterspec_propagation is true, the session
             states are shared.
             - If share_session_state_in_clusterspec_propagation is false, session
             states are isolated.

             When clusterspec propagation is not used, the value of
             share_session_state_in_clusterspec_propagation is ignored when deciding
             whether to share session states in a TF server.
             - If isolate_session_state is true, session states are isolated.
             - If isolate_session_state is false, session states are shared.

             TODO(b/129330037): Add a single API that consistently treats
             isolate_session_state and ClusterSpec propagation.
        disableThreadSpinning:
          type: boolean
          title: disable_thread_spinning
          description: |-
            If using a direct session, disable spinning while waiting for work in
             the thread pool. This may result in higher latency for completing ops,
             but in the case where there is a lot of spinning may result in lower
             CPU usage.
        shareClusterDevicesInSession:
          type: boolean
          title: share_cluster_devices_in_session
          description: |-
            This was promoted to a non-experimental API. Please use
             ConfigProto.share_cluster_devices_in_session instead.
        sessionMetadata:
          allOf:
            - title: session_metadata
              description: |-
                Metadata about the session.

                 If set, this can be used by the runtime and the Ops for debugging,
                 monitoring, etc.

                 NOTE: This is currently used and propagated only by the direct session
                 and EagerContext.
            - $ref: '#/components/schemas/tensorflow.SessionMetadata'
        optimizeForStaticGraph:
          type: boolean
          title: optimize_for_static_graph
          description: |-
            If true, the session may treat the graph as being static for optimization
             purposes.

             If this option is set to true when a session is created, the full
             GraphDef must be passed in a single call to Session::Create(), and
             Session::Extend() may not be supported.
        enableMlirBridge:
          type: boolean
          title: enable_mlir_bridge
          description: |-
            Whether to enable the MLIR-based TF->XLA bridge. This is only used if set
             to true. Default value or false is ignored. Use mlir_bridge_rollout for
             finer control.

             If this option is set to true when a session is created, MLIR is used to
             perform the set of graph transformations to put the graph in a form that
             can be executed with delegation of some computations to an accelerator.
             This builds on the model of XLA where a subset of the graph is
             encapsulated and attached to a "compile" operation, whose result is fed
             to an "execute" operation. The kernel for these operations is responsible
             to lower the encapsulated graph to a particular device.
        mlirBridgeRollout:
          allOf:
            - title: mlir_bridge_rollout
              description: Whether to enable the MLIR-based TF->XLA bridge.
            - $ref: '#/components/schemas/tensorflow.ConfigProto.Experimental.MlirBridgeRollout'
        enableMlirGraphOptimization:
          type: boolean
          title: enable_mlir_graph_optimization
          description: |-
            Whether to enable the MLIR-based Graph optimizations.

             This will become a part of standard Tensorflow graph optimization
             pipeline, currently this is only used for gradual migration and testing
             new passes that are replacing existing optimizations in Grappler.
        disableOutputPartitionGraphs:
          type: boolean
          title: disable_output_partition_graphs
          description: |-
            If true, the session will not store an additional copy of the graph for
             each subgraph.

             If this option is set to true when a session is created, the
             `RunOptions.output_partition_graphs` options must not be set.
        xlaFusionAutotunerThresh:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: xla_fusion_autotuner_thresh
          description: |-
            Minimum number of batches run through the XLA graph before XLA fusion
             autotuner is enabled. Default value of zero disables the autotuner.

             The XLA fusion autotuner can improve performance by executing a heuristic
             search on the compiler parameters.
        useTfrt:
          type: boolean
          title: use_tfrt
          description: Whether runtime execution uses TFRT.
        disableFunctionalOpsLowering:
          type: boolean
          title: disable_functional_ops_lowering
          description: |-
            Whether functional control flow op lowering should be disabled. This is
             useful when executing within a portable runtime where control flow op
             kernels may not be loaded due to selective registration.
        xlaPreferSingleGraphCluster:
          type: boolean
          title: xla_prefer_single_graph_cluster
          description: |-
            Provides a hint to XLA auto clustering to prefer forming a single large
             cluster that encompases most of the graph.
        coordinationConfig:
          allOf:
            - title: coordination_config
              description: Distributed coordination service configurations.
            - $ref: '#/components/schemas/tensorflow.CoordinationServiceConfig'
        disableOptimizeForStaticGraph:
          type: boolean
          title: disable_optimize_for_static_graph
          description: |-
            If true, the session will treat the graph as being non-static for
             optimization purposes.

             If this option is set to true when a session is created, the full
             GraphDef will be retained to enable calls to Session::Extend().
             Calling Extend() without setting this flag will result in errors.

             This option is meant to replace `optimize_for_static_graph` and it
             aims to negate its value.
      title: Experimental
      additionalProperties: false
      description: |-
        Everything inside Experimental is subject to change and is not subject
         to API stability guarantees in
         https://www.tensorflow.org/guide/version_compat.
    tensorflow.CoordinatedJob:
      type: object
      properties:
        name:
          type: string
          title: name
        numTasks:
          type: integer
          title: num_tasks
          format: int32
      title: CoordinatedJob
      additionalProperties: false
      description: |-
        Represents a job type and the number of tasks under this job.
         For example, ("worker", 20) implies that there will be 20 worker tasks.
    tensorflow.CoordinationServiceConfig:
      type: object
      properties:
        serviceType:
          type: string
          title: service_type
          description: |-
            Type of coordination service implementation to enable.
             For example, setting the service type as "standalone" starts a service
             instance on the leader task to provide the coordination services such as
             heartbeats and consistent key-value store.
        serviceLeader:
          type: string
          title: service_leader
          description: Address where the coordination service instance is hosted.
        enableHealthCheck:
          type: boolean
          title: enable_health_check
          description: Whether to enable the health check mechanism.
        clusterRegisterTimeoutInMs:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: cluster_register_timeout_in_ms
          description: Maximum wait time for all members in the cluster to be registered.
        heartbeatTimeoutInMs:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: heartbeat_timeout_in_ms
          description: |-
            Heartbeat timeout, if a task does not record heartbeat in this time
             window, it will be considered disconnected.
             Note: This is also used as a grace period to accept any heartbeats after
             the agent has disconnected, to account for the lag time between the service
             recording the state change and the agent stopping heartbeats.
        coordinatedJobList:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.CoordinatedJob'
          title: coordinated_job_list
        shutdownBarrierTimeoutInMs:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: shutdown_barrier_timeout_in_ms
          description: |-
            Denotes how long to wait for all coordination agents to reach the barriers
             (after the first shutdown request) before disconnecting together. If
             set to 0, no barrier is imposed upon shutdown and each worker can
             disconnect individually.
        agentDestructionWithoutShutdown:
          type: boolean
          title: agent_destruction_without_shutdown
          description: |-
            If set, agents do not make an explicit Shutdown() call. Service will only
             find out about the disconnecte agent via stale heartbeats. Used for
             testing.
        recoverableJobs:
          type: array
          items:
            type: string
          title: recoverable_jobs
          description: |-
            The list of jobs which are recoverable. If a task in this list fails,
             it will not propagate error to other tasks.
             If empty, no jobs will be recoverable and every task failure will cause
             error propagation to other tasks.
        allowNewIncarnationToReconnect:
          type: boolean
          title: allow_new_incarnation_to_reconnect
          description: |-
            If a task restarts with a new incarnation, we may allow it to reconnect
             silently. This is useful when we know that a task can immediately resume
             work upon re-connecting to the service.
      title: CoordinationServiceConfig
      additionalProperties: false
      description: |-
        Coordination service configuration parameters.
         The system picks appropriate values for fields that are not set.
    tensorflow.CostGraphDef:
      type: object
      properties:
        node:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.CostGraphDef.Node'
          title: node
        cost:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.CostGraphDef.AggregatedCost'
          title: cost
      title: CostGraphDef
      additionalProperties: false
    tensorflow.CostGraphDef.AggregatedCost:
      type: object
      properties:
        cost:
          type: number
          title: cost
          format: float
          description: Aggregated cost value.
        dimension:
          type: string
          title: dimension
          description: Aggregated cost dimension (e.g. 'memory', 'compute', 'network').
      title: AggregatedCost
      additionalProperties: false
      description: Total cost of this graph, typically used for balancing decisions.
    tensorflow.CostGraphDef.Node:
      type: object
      properties:
        name:
          type: string
          title: name
          description: The name of the node. Names are globally unique.
        device:
          type: string
          title: device
          description: |-
            The device of the node. Can be empty if the node is mapped to the
             default partition or partitioning hasn't been run yet.
        id:
          type: integer
          title: id
          format: int32
          description: The id of the node. Node ids are only unique inside a partition.
        inputInfo:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.CostGraphDef.Node.InputInfo'
          title: input_info
        outputInfo:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.CostGraphDef.Node.OutputInfo'
          title: output_info
        temporaryMemorySize:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: temporary_memory_size
          description: Temporary memory used by this node.
        persistentMemorySize:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: persistent_memory_size
          description: Persistent memory used by this node.
        hostTempMemorySize:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: host_temp_memory_size
        deviceTempMemorySize:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: device_temp_memory_size
        devicePersistentMemorySize:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: device_persistent_memory_size
        computeCost:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: compute_cost
          description: Estimate of the computational cost of this node, in microseconds.
        computeTime:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: compute_time
          description: |-
            Analytical estimate of the computational cost of this node, in
             microseconds.
        memoryTime:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: memory_time
          description: |-
            Analytical estimate of the memory access cost of this node, in
             microseconds.
        isFinal:
          type: boolean
          title: is_final
          description: |-
            If true, the output is permanent: it can't be discarded, because this
             node is part of the "final output". Nodes may depend on final nodes.
        controlInput:
          type: array
          items:
            type: integer
            format: int32
          title: control_input
          description: Ids of the control inputs for this node.
        inaccurate:
          type: boolean
          title: inaccurate
          description: Are the costs inaccurate?
      title: Node
      additionalProperties: false
    tensorflow.CostGraphDef.Node.InputInfo:
      type: object
      properties:
        precedingNode:
          type: integer
          title: preceding_node
          format: int32
        precedingPort:
          type: integer
          title: preceding_port
          format: int32
      title: InputInfo
      additionalProperties: false
      description: |-
        Inputs of this node. They must be executed before this node can be
         executed. An input is a particular output of another node, specified
         by the node id and the output index.
    tensorflow.CostGraphDef.Node.OutputInfo:
      type: object
      properties:
        size:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: size
        aliasInputPort:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: alias_input_port
          description: |-
            If >= 0, the output is an alias of an input. Note that an alias input
             may itself be an alias. The algorithm will therefore need to follow
             those pointers.
        shape:
          allOf:
            - title: shape
            - $ref: '#/components/schemas/tensorflow.TensorShapeProto'
        dtype:
          allOf:
            - title: dtype
            - $ref: '#/components/schemas/tensorflow.DataType'
      title: OutputInfo
      additionalProperties: false
      description: Outputs of this node.
    tensorflow.CreateSessionRequest:
      type: object
      properties:
        graphDef:
          allOf:
            - title: graph_def
              description: The initial graph definition.
            - $ref: '#/components/schemas/tensorflow.GraphDef'
        config:
          allOf:
            - title: config
              description: Configuration options.
            - $ref: '#/components/schemas/tensorflow.ConfigProto'
        target:
          type: string
          title: target
          description: The target string used from the client's perspective.
      title: CreateSessionRequest
      additionalProperties: false
    tensorflow.CreateSessionResponse:
      type: object
      properties:
        sessionHandle:
          type: string
          title: session_handle
          description: |-
            The session handle to be used in subsequent calls for the created session.

             The client must arrange to call CloseSession with this returned
             session handle to close the session.
        graphVersion:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: graph_version
          description: |-
            The initial version number for the graph, to be used in the next call
             to ExtendSession.
      title: CreateSessionResponse
      additionalProperties: false
    tensorflow.DebugOptions:
      type: object
      properties:
        debugTensorWatchOpts:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.DebugTensorWatch'
          title: debug_tensor_watch_opts
          description: Debugging options
        globalStep:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: global_step
          description: |-
            Caller-specified global step count.
             Note that this is distinct from the session run count and the executor
             step count.
        resetDiskByteUsage:
          type: boolean
          title: reset_disk_byte_usage
          description: |-
            Whether the total disk usage of tfdbg is to be reset to zero
             in this Session.run call. This is used by wrappers and hooks
             such as the local CLI ones to indicate that the dumped tensors
             are cleaned up from the disk after each Session.run.
      title: DebugOptions
      additionalProperties: false
      description: Options for initializing DebuggerState in TensorFlow Debugger (tfdbg).
    tensorflow.DebugTensorWatch:
      type: object
      properties:
        nodeName:
          type: string
          title: node_name
          description: |-
            Name of the node to watch.
             Use "*" for wildcard. But note: currently, regex is not supported in
             general.
        outputSlot:
          type: integer
          title: output_slot
          format: int32
          description: |-
            Output slot to watch.
             The semantics of output_slot == -1 is that all outputs of the node
             will be watched (i.e., a wildcard).
             Other negative values of output_slot are invalid and will lead to
             errors currently.
        debugOps:
          type: array
          items:
            type: string
          title: debug_ops
          description: |-
            Name(s) of the debugging op(s).
             One or more than one probes on a tensor.
             e.g., {"DebugIdentity", "DebugNanCount"}
        debugUrls:
          type: array
          items:
            type: string
          title: debug_urls
          description: |-
            URL(s) for debug targets(s).

             Supported URL formats are:
               - file:///foo/tfdbg_dump: Writes out Event content to file
                 /foo/tfdbg_dump.  Assumes all directories can be created if they don't
                 already exist.
               - grpc://localhost:11011: Sends an RPC request to an EventListener
                 service running at localhost:11011 with the event.
               - memcbk:///event_key: Routes tensors to clients using the
                 callback registered with the DebugCallbackRegistry for event_key.

             Each debug op listed in debug_ops will publish its output tensor (debug
             signal) to all URLs in debug_urls.

             N.B. Session::Run() supports concurrent invocations of the same inputs
             (feed keys), outputs and target nodes. If such concurrent invocations
             are to be debugged, the callers of Session::Run() must use distinct
             debug_urls to make sure that the streamed or dumped events do not overlap
             among the invocations.
             TODO(cais): More visible documentation of this in g3docs.
        tolerateDebugOpCreationFailures:
          type: boolean
          title: tolerate_debug_op_creation_failures
          description: |-
            Do not error out if debug op creation fails (e.g., due to dtype
             incompatibility). Instead, just log the failure.
      title: DebugTensorWatch
      additionalProperties: false
      description: Option for watching a node in TensorFlow Debugger (tfdbg).
    tensorflow.DeviceAttributes:
      type: object
      properties:
        name:
          type: string
          title: name
          description: Fully specified name of the device within a cluster.
        deviceType:
          type: string
          title: device_type
          description: String representation of device_type.
        memoryLimit:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: memory_limit
          description: Memory capacity of device in bytes.
        locality:
          allOf:
            - title: locality
              description: |-
                Platform-specific data about device that may be useful
                 for supporting efficient data transfers.
            - $ref: '#/components/schemas/tensorflow.DeviceLocality'
        incarnation:
          oneOf:
            - type: string
            - type: integer
          title: incarnation
          description: |-
            A device is assigned a global unique number each time it is
             initialized. "incarnation" should never be 0.
        physicalDeviceDesc:
          type: string
          title: physical_device_desc
          description: String representation of the physical device that this device maps to.
        xlaGlobalId:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: xla_global_id
          description: |-
            A physical device ID for use in XLA DeviceAssignments, unique across
             clients in a multi-client setup. Set to -1 if unavailable, non-negative
             otherwise.
      title: DeviceAttributes
      additionalProperties: false
    tensorflow.DeviceLocality:
      type: object
      properties:
        busId:
          type: integer
          title: bus_id
          format: int32
          description: |-
            Optional bus locality of device.  Default value of 0 means
             no specific locality.  Specific localities are indexed from 1.
        numaNode:
          type: integer
          title: numa_node
          format: int32
          description: Optional NUMA locality of device.
        links:
          allOf:
            - title: links
              description: Optional local interconnect links to other devices.
            - $ref: '#/components/schemas/tensorflow.LocalLinks'
      title: DeviceLocality
      additionalProperties: false
    tensorflow.DeviceStepStats:
      type: object
      properties:
        device:
          type: string
          title: device
        nodeStats:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.NodeExecStats'
          title: node_stats
        threadNames:
          type: object
          title: thread_names
          additionalProperties:
            type: string
            title: value
          description: Its key is thread id.
      title: DeviceStepStats
      additionalProperties: false
    tensorflow.DeviceStepStats.ThreadNamesEntry:
      type: object
      properties:
        key:
          type: integer
          title: key
        value:
          type: string
          title: value
      title: ThreadNamesEntry
      additionalProperties: false
    tensorflow.ExtendSessionRequest:
      type: object
      properties:
        sessionHandle:
          type: string
          title: session_handle
          description: |-
            REQUIRED: session_handle must be returned by a CreateSession call
             to the same master service.
        graphDef:
          allOf:
            - title: graph_def
              description: |-
                REQUIRED: The nodes to be added to the session's graph. If any node has
                 the same name as an existing node, the operation will fail with
                 ILLEGAL_ARGUMENT.
            - $ref: '#/components/schemas/tensorflow.GraphDef'
        currentGraphVersion:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: current_graph_version
          description: |-
            REQUIRED: The version number of the graph to be extended. This will be
             tested against the current server-side version number, and the operation
             will fail with FAILED_PRECONDITION if they do not match.
      title: ExtendSessionRequest
      additionalProperties: false
    tensorflow.ExtendSessionResponse:
      type: object
      properties:
        newGraphVersion:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: new_graph_version
          description: |-
            The new version number for the extended graph, to be used in the next call
             to ExtendSession.
      title: ExtendSessionResponse
      additionalProperties: false
      description: 'TODO(mrry): Return something about the operation?'
    tensorflow.FullTypeDef:
      type: object
      allOf:
        - anyOf:
            - required:
                - i
            - required:
                - s
            - not:
                anyOf:
                  - required:
                      - i
                  - required:
                      - s
      anyOf:
        - required:
            - i
        - required:
            - s
        - not:
            anyOf:
              - required:
                  - i
              - required:
                  - s
      properties:
        typeId:
          allOf:
            - title: type_id
              description: |-
                The principal type represented by this object. This may be a concrete type
                 (Tensor, Dataset) a type variable (used for dependent types) a type
                 symbol (Any, Union). See FullTypeId for details.
            - $ref: '#/components/schemas/tensorflow.FullTypeId'
        args:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.FullTypeDef'
          title: args
        s:
          type: string
          title: s
        i:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: i
          description: 'TODO(mdan): list/tensor, map? Need to reconcile with TFT_RECORD, etc.'
      title: FullTypeDef
      additionalProperties: false
      description: |-
        Highly experimental and very likely to change.
         This encoding uses tags instead of dedicated messages for regularity. In
         particular the encoding imposes no restrictions on what the parameters of any
         type should be, which in particular needs to be true for type symbols.
    tensorflow.FunctionDef:
      type: object
      properties:
        signature:
          allOf:
            - title: signature
              description: |-
                The definition of the function's name, arguments, return values,
                 attrs etc.
            - $ref: '#/components/schemas/tensorflow.OpDef'
        attr:
          type: object
          title: attr
          additionalProperties:
            allOf:
              - title: value
              - $ref: '#/components/schemas/tensorflow.AttrValue'
          description: Attributes specific to this function definition.
        argAttr:
          type: object
          title: arg_attr
          additionalProperties:
            allOf:
              - title: value
              - $ref: '#/components/schemas/tensorflow.FunctionDef.ArgAttrs'
        resourceArgUniqueId:
          type: object
          title: resource_arg_unique_id
          additionalProperties:
            type: integer
            title: value
          description: |-
            Unique IDs for each resource argument, used to track aliasing resources. If
             Argument A and Argument B alias each other, then
             resource_arg_unique_ids[A.index] == resource_arg_unique_ids[B.index].

             If this field is empty, none of the arguments could alias; otherwise, every
             resource argument should have an entry in this field.

             When instantiated, the unique IDs will be attached to the _Arg nodes'
             "_resource_arg_unique_id" attribute.
        nodeDef:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.NodeDef'
          title: node_def
          description: |-
            By convention, "op" in node_def is resolved by consulting with a
             user-defined library first. If not resolved, "func" is assumed to
             be a builtin op.
        ret:
          type: object
          title: ret
          additionalProperties:
            type: string
            title: value
          description: |-
            A mapping from the output arg names from `signature` to the
             outputs from `node_def` that should be returned by the function.
        controlRet:
          type: object
          title: control_ret
          additionalProperties:
            type: string
            title: value
          description: |-
            A mapping from control output names from `signature` to node names in
             `node_def` which should be control outputs of this function.
      title: FunctionDef
      additionalProperties: false
      description: |-
        A function can be instantiated when the runtime can bind every attr
         with a value. When a GraphDef has a call to a function, it must
         have binding for every attr defined in the signature.

         TODO(zhifengc):
           * device spec, etc.
    tensorflow.FunctionDef.ArgAttrEntry:
      type: object
      properties:
        key:
          type: integer
          title: key
        value:
          allOf:
            - title: value
            - $ref: '#/components/schemas/tensorflow.FunctionDef.ArgAttrs'
      title: ArgAttrEntry
      additionalProperties: false
    tensorflow.FunctionDef.ArgAttrs:
      type: object
      properties:
        attr:
          type: object
          title: attr
          additionalProperties:
            allOf:
              - title: value
              - $ref: '#/components/schemas/tensorflow.AttrValue'
      title: ArgAttrs
      additionalProperties: false
      description: |-
        Attributes for function arguments. These attributes are the same set of
         valid attributes as to _Arg nodes.
    tensorflow.FunctionDef.ArgAttrs.AttrEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          allOf:
            - title: value
            - $ref: '#/components/schemas/tensorflow.AttrValue'
      title: AttrEntry
      additionalProperties: false
    tensorflow.FunctionDef.AttrEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          allOf:
            - title: value
            - $ref: '#/components/schemas/tensorflow.AttrValue'
      title: AttrEntry
      additionalProperties: false
    tensorflow.FunctionDef.ControlRetEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          type: string
          title: value
      title: ControlRetEntry
      additionalProperties: false
    tensorflow.FunctionDef.ResourceArgUniqueIdEntry:
      type: object
      properties:
        key:
          type: integer
          title: key
        value:
          type: integer
          title: value
      title: ResourceArgUniqueIdEntry
      additionalProperties: false
    tensorflow.FunctionDef.RetEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          type: string
          title: value
      title: RetEntry
      additionalProperties: false
    tensorflow.FunctionDefLibrary:
      type: object
      properties:
        function:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.FunctionDef'
          title: function
        gradient:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.GradientDef'
          title: gradient
        registeredGradients:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.RegisteredGradient'
          title: registered_gradients
      title: FunctionDefLibrary
      additionalProperties: false
      description: A library is a set of named functions.
    tensorflow.GPUOptions:
      type: object
      properties:
        perProcessGpuMemoryFraction:
          type: number
          title: per_process_gpu_memory_fraction
          format: double
          description: |-
            Fraction of the total GPU memory to allocate for each process.
             1 means to allocate all of the GPU memory, 0.5 means the process
             allocates up to ~50% of the total GPU memory.

             GPU memory is pre-allocated unless the allow_growth option is enabled.

             If greater than 1.0, uses CUDA unified memory to potentially oversubscribe
             the amount of memory available on the GPU device by using host memory as a
             swap space. Accessing memory not available on the device will be
             significantly slower as that would require memory transfer between the host
             and the device. Options to reduce the memory requirement should be
             considered before enabling this option as this may come with a negative
             performance impact. Oversubscription using the unified memory requires
             Pascal class or newer GPUs and it is currently only supported on the Linux
             operating system. See
             https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
             for the detailed requirements.
        allowGrowth:
          type: boolean
          title: allow_growth
          description: |-
            If true, the allocator does not pre-allocate the entire specified
             GPU memory region, instead starting small and growing as needed.
        allocatorType:
          type: string
          title: allocator_type
          description: |-
            The type of GPU allocation strategy to use.

             Allowed values:
             "": The empty string (default) uses a system-chosen default
                 which may change over time.

             "BFC": A "Best-fit with coalescing" algorithm, simplified from a
                    version of dlmalloc.
        deferredDeletionBytes:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: deferred_deletion_bytes
          description: |-
            Delay deletion of up to this many bytes to reduce the number of
             interactions with gpu driver code.  If 0, the system chooses
             a reasonable default (several MBs).
        visibleDeviceList:
          type: string
          title: visible_device_list
          description: |-
            A comma-separated list of GPU ids that determines the 'visible'
             to 'virtual' mapping of GPU devices.  For example, if TensorFlow
             can see 8 GPU devices in the process, and one wanted to map
             visible GPU devices 5 and 3 as "/device:GPU:0", and "/device:GPU:1",
             then one would specify this field as "5,3".  This field is similar in
             spirit to the CUDA_VISIBLE_DEVICES environment variable, except
             it applies to the visible GPU devices in the process.

             NOTE:
             1. The GPU driver provides the process with the visible GPUs
                in an order which is not guaranteed to have any correlation to
                the *physical* GPU id in the machine.  This field is used for
                remapping "visible" to "virtual", which means this operates only
                after the process starts.  Users are required to use vendor
                specific mechanisms (e.g., CUDA_VISIBLE_DEVICES) to control the
                physical to visible device mapping prior to invoking TensorFlow.
             2. In the code, the ids in this list are also called "platform GPU id"s,
                and the 'virtual' ids of GPU devices (i.e. the ids in the device
                name "/device:GPU:<id>") are also called "TF GPU id"s. Please
                refer to third_party/tensorflow/core/common_runtime/gpu/gpu_id.h
                for more information.
        pollingActiveDelayUsecs:
          type: integer
          title: polling_active_delay_usecs
          format: int32
          description: |-
            In the event polling loop sleep this many microseconds between
             PollEvents calls, when the queue is not empty.  If value is not
             set or set to 0, gets set to a non-zero default.
        pollingInactiveDelayMsecs:
          type: integer
          title: polling_inactive_delay_msecs
          format: int32
          description: This field is deprecated and ignored.
        forceGpuCompatible:
          type: boolean
          title: force_gpu_compatible
          description: |-
            Force all tensors to be gpu_compatible. On a GPU-enabled TensorFlow,
             enabling this option forces all CPU tensors to be allocated with Cuda
             pinned memory. Normally, TensorFlow will infer which tensors should be
             allocated as the pinned memory. But in case where the inference is
             incomplete, this option can significantly speed up the cross-device memory
             copy performance as long as it fits the memory.
             Note that this option is not something that should be
             enabled by default for unknown or very large models, since all Cuda pinned
             memory is unpageable, having too much pinned memory might negatively impact
             the overall host system performance.
        experimental:
          allOf:
            - title: experimental
              description: |-
                Everything inside experimental is subject to change and is not subject
                 to API stability guarantees in
                 https://www.tensorflow.org/guide/version_compat.
            - $ref: '#/components/schemas/tensorflow.GPUOptions.Experimental'
      title: GPUOptions
      additionalProperties: false
    tensorflow.GPUOptions.Experimental:
      type: object
      properties:
        virtualDevices:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.GPUOptions.Experimental.VirtualDevices'
          title: virtual_devices
          description: |-
            The multi virtual device settings. If empty (not set), it will create
             single virtual device on each visible GPU, according to the settings
             in "visible_device_list" above. Otherwise, the number of elements in the
             list must be the same as the number of visible GPUs (after
             "visible_device_list" filtering if it is set), and the string represented
             device names (e.g. /device:GPU:<id>) will refer to the virtual
             devices and have the <id> field assigned sequentially starting from 0,
             according to the order of the virtual devices determined by
             device_ordinal and the location in the virtual device list.

             For example,
               visible_device_list = "1,0"
               virtual_devices { memory_limit: 1GB memory_limit: 2GB }
               virtual_devices { memory_limit: 3GB memory_limit: 4GB }
             will create 4 virtual devices as:
               /device:GPU:0 -> visible GPU 1 with 1GB memory
               /device:GPU:1 -> visible GPU 1 with 2GB memory
               /device:GPU:2 -> visible GPU 0 with 3GB memory
               /device:GPU:3 -> visible GPU 0 with 4GB memory

             but
               visible_device_list = "1,0"
               virtual_devices { memory_limit: 1GB memory_limit: 2GB
                                 device_ordinal: 10 device_ordinal: 20}
               virtual_devices { memory_limit: 3GB memory_limit: 4GB
                                 device_ordinal: 10 device_ordinal: 20}
             will create 4 virtual devices as:
               /device:GPU:0 -> visible GPU 1 with 1GB memory  (ordinal 10)
               /device:GPU:1 -> visible GPU 0 with 3GB memory  (ordinal 10)
               /device:GPU:2 -> visible GPU 1 with 2GB memory  (ordinal 20)
               /device:GPU:3 -> visible GPU 0 with 4GB memory  (ordinal 20)

             NOTE:
             1. It's invalid to set both this and "per_process_gpu_memory_fraction"
                at the same time.
             2. Currently this setting is per-process, not per-session. Using
                different settings in different sessions within same process will
                result in undefined behavior.
        useUnifiedMemory:
          type: boolean
          title: use_unified_memory
          description: |-
            If true, uses CUDA unified memory for memory allocations. If
             per_process_gpu_memory_fraction option is greater than 1.0, then unified
             memory is used regardless of the value for this field. See comments for
             per_process_gpu_memory_fraction field for more details and requirements
             of the unified memory. This option is useful to oversubscribe memory if
             multiple processes are sharing a single GPU while individually using less
             than 1.0 per process memory fraction.
        numDevToDevCopyStreams:
          type: integer
          title: num_dev_to_dev_copy_streams
          format: int32
          description: |-
            If > 1, the number of device-to-device copy streams to create
             for each GPUDevice.  Default value is 0, which is automatically
             converted to 1.
        collectiveRingOrder:
          type: string
          title: collective_ring_order
          description: |-
            If non-empty, defines a good GPU ring order on a single worker based on
             device interconnect.  This assumes that all workers have the same GPU
             topology.  Specify as a comma-separated string, e.g. "3,2,1,0,7,6,5,4".
             This ring order is used by the RingReducer implementation of
             CollectiveReduce, and serves as an override to automatic ring order
             generation in OrderTaskDeviceMap() during CollectiveParam resolution.
        timestampedAllocator:
          type: boolean
          title: timestamped_allocator
          description: |-
            If true then extra work is done by GPUDevice and GPUBFCAllocator to
             keep track of when GPU memory is freed and when kernels actually
             complete so that we can know when a nominally free memory chunk
             is really not subject to pending use.
        kernelTrackerMaxInterval:
          type: integer
          title: kernel_tracker_max_interval
          format: int32
          description: |-
            Parameters for GPUKernelTracker.  By default no kernel tracking is done.
             Note that timestamped_allocator is only effective if some tracking is
             specified.

             If kernel_tracker_max_interval = n > 0, then a tracking event
             is inserted after every n kernels without an event.
        kernelTrackerMaxBytes:
          type: integer
          title: kernel_tracker_max_bytes
          format: int32
          description: |-
            If kernel_tracker_max_bytes = n > 0, then a tracking event is
             inserted after every series of kernels allocating a sum of
             memory >= n.  If one kernel allocates b * n bytes, then one
             event will be inserted after it, but it will count as b against
             the pending limit.
        kernelTrackerMaxPending:
          type: integer
          title: kernel_tracker_max_pending
          format: int32
          description: |-
            If kernel_tracker_max_pending > 0 then no more than this many
             tracking events can be outstanding at a time.  An attempt to
             launch an additional kernel will stall until an event
             completes.
        internalFragmentationFraction:
          type: number
          title: internal_fragmentation_fraction
          format: double
          description: |-
            BFC Allocator can return an allocated chunk of memory upto 2x the
             requested size. For virtual devices with tight memory constraints, and
             proportionately large allocation requests, this can lead to a significant
             reduction in available memory. The threshold below controls when a chunk
             should be split if the chunk size exceeds requested memory size. It is
             expressed as a fraction of total available memory for the tf device. For
             example setting it to 0.05 would imply a chunk needs to be split if its
             size exceeds the requested memory by 5% of the total virtual device/gpu
             memory size.
        useCudaMallocAsync:
          type: boolean
          title: use_cuda_malloc_async
          description: When true, use CUDA cudaMallocAsync API instead of TF gpu allocator.
        disallowRetryOnAllocationFailure:
          type: boolean
          title: disallow_retry_on_allocation_failure
          description: |-
            By default, BFCAllocator may sleep when it runs out of memory, in the
             hopes that another thread will free up memory in the meantime.  Setting
             this to true disables the sleep; instead we'll OOM immediately.
        gpuHostMemLimitInMb:
          type: number
          title: gpu_host_mem_limit_in_mb
          format: float
          description: |-
            Memory limit for "GPU host allocator", aka pinned memory allocator.  This
             can also be set via the envvar TF_GPU_HOST_MEM_LIMIT_IN_MB.
        gpuHostMemDisallowGrowth:
          type: boolean
          title: gpu_host_mem_disallow_growth
          description: |-
            If true, then the host allocator allocates its max memory all upfront and
             never grows.  This can be useful for latency-sensitive systems, because
             growing the GPU host memory pool can be expensive.

             You probably only want to use this in combination with
             gpu_host_mem_limit_in_mb, because the default GPU host memory limit is
             quite high.
      title: Experimental
      additionalProperties: false
    tensorflow.GPUOptions.Experimental.VirtualDevices:
      type: object
      properties:
        memoryLimitMb:
          type: array
          items:
            type: number
            format: float
          title: memory_limit_mb
          description: |-
            Per "virtual" device memory limit, in MB. The number of elements in
             the list is the number of virtual devices to create on the
             corresponding visible GPU (see "virtual_devices" below).
             If empty, it will create single virtual device taking all available
             memory from the device.

             For the concept of "visible" and "virtual" GPU, see the comments for
             "visible_device_list" above for more information.
        priority:
          type: array
          items:
            type: integer
            format: int32
          title: priority
          description: |-
            Priority values to use with the virtual devices. Use the cuda function
             cudaDeviceGetStreamPriorityRange to query for valid range of values for
             priority.

             On a P4000 GPU with cuda 10.1, the priority range reported was 0 for
             least priority and -1 for greatest priority.

             If this field is not specified, then the virtual devices will be
             created with the default. If this field has values set, then the size
             of this must match with the above memory_limit_mb.
        deviceOrdinal:
          type: array
          items:
            type: integer
            format: int32
          title: device_ordinal
          description: |-
            Virtual Device ordinal number determines the device ID of the device.
             A Virtual device with a lower ordinal number always receives the a
             smaller device id. The phyiscal device id and location in the
             virtual device list is used to break ties.
      title: VirtualDevices
      additionalProperties: false
      description: |-
        Configuration for breaking down a visible GPU into multiple "virtual"
         devices.
    tensorflow.GradientDef:
      type: object
      properties:
        functionName:
          type: string
          title: function_name
          description: The function name.
        gradientFunc:
          type: string
          title: gradient_func
          description: The gradient function's name.
      title: GradientDef
      additionalProperties: false
      description: |-
        GradientDef defines the gradient function of a function defined in
         a function library.

         A gradient function g (specified by gradient_func) for a function f
         (specified by function_name) must follow the following:

         The function 'f' must be a numerical function which takes N inputs
         and produces M outputs. Its gradient function 'g', which is a
         function taking N + M inputs and produces N outputs.

         I.e. if we have
            (y1, y2, ..., y_M) = f(x1, x2, ..., x_N),
         then, g is
            (dL/dx1, dL/dx2, ..., dL/dx_N) = g(x1, x2, ..., x_N,
                                              dL/dy1, dL/dy2, ..., dL/dy_M),
         where L is a scalar-value function of (x1, x2, ..., xN) (e.g., the
         loss function). dL/dx_i is the partial derivative of L with respect
         to x_i.
    tensorflow.GraphDebugInfo:
      type: object
      properties:
        files:
          type: array
          items:
            type: string
          title: files
          description: |-
            This stores all the source code file names and can be indexed by the
             `file_index`.
        framesById:
          type: object
          title: frames_by_id
          additionalProperties:
            allOf:
              - title: value
              - $ref: '#/components/schemas/tensorflow.GraphDebugInfo.FileLineCol'
          description: |-
            Stack traces and frames are uniqueified during construction. These maps
             index from the unique id for a frame/trace to the value.
        tracesById:
          type: object
          title: traces_by_id
          additionalProperties:
            allOf:
              - title: value
              - $ref: '#/components/schemas/tensorflow.GraphDebugInfo.StackTrace'
        traces:
          type: object
          title: traces
          additionalProperties:
            allOf:
              - title: value
              - $ref: '#/components/schemas/tensorflow.GraphDebugInfo.StackTrace'
          description: Deprecated.
        nameToTraceId:
          type: object
          title: name_to_trace_id
          additionalProperties:
            oneOf:
              - type: string
              - type: integer
            title: value
          description: |-
            This maps a node name to a trace id contained in `traces_by_id`.

             The map key is a mangling of the containing function and op name with
             syntax:
               op.name '@' func_name
             For ops in the top-level graph, the func_name is the empty string and hence
             the `@` may be ommitted.
             Note that op names are restricted to a small number of characters which
             exclude '@', making it impossible to collide keys of this form. Function
             names accept a much wider set of characters.
             It would be preferable to avoid mangling and use a tuple key of (op.name,
             func_name), but this is not supported with protocol buffers.
      title: GraphDebugInfo
      additionalProperties: false
    tensorflow.GraphDebugInfo.FileLineCol:
      type: object
      properties:
        fileIndex:
          type: integer
          title: file_index
          format: int32
          description: |-
            File name index, which can be used to retrieve the file name string from
             `files`. The value should be between 0 and (len(files)-1)
        line:
          type: integer
          title: line
          format: int32
          description: Line number in the file.
        col:
          type: integer
          title: col
          format: int32
          description: Col number in the file line.
        func:
          type: string
          title: func
          description: Name of function contains the file line.
        code:
          type: string
          title: code
          description: Source code contained in this file line.
      title: FileLineCol
      additionalProperties: false
      description: This represents a file/line location in the source code.
    tensorflow.GraphDebugInfo.FramesByIdEntry:
      type: object
      properties:
        key:
          oneOf:
            - type: string
            - type: integer
          title: key
        value:
          allOf:
            - title: value
            - $ref: '#/components/schemas/tensorflow.GraphDebugInfo.FileLineCol'
      title: FramesByIdEntry
      additionalProperties: false
    tensorflow.GraphDebugInfo.NameToTraceIdEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          oneOf:
            - type: string
            - type: integer
          title: value
      title: NameToTraceIdEntry
      additionalProperties: false
    tensorflow.GraphDebugInfo.StackTrace:
      type: object
      properties:
        fileLineCols:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.GraphDebugInfo.FileLineCol'
          title: file_line_cols
          description: Deprecated.
        frameId:
          type: array
          items:
            oneOf:
              - type: string
              - type: integer
          title: frame_id
      title: StackTrace
      additionalProperties: false
      description: This represents a stack trace which is a ordered list of `FileLineCol`.
    tensorflow.GraphDebugInfo.TracesByIdEntry:
      type: object
      properties:
        key:
          oneOf:
            - type: string
            - type: integer
          title: key
        value:
          allOf:
            - title: value
            - $ref: '#/components/schemas/tensorflow.GraphDebugInfo.StackTrace'
      title: TracesByIdEntry
      additionalProperties: false
    tensorflow.GraphDebugInfo.TracesEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          allOf:
            - title: value
            - $ref: '#/components/schemas/tensorflow.GraphDebugInfo.StackTrace'
      title: TracesEntry
      additionalProperties: false
    tensorflow.GraphDef:
      type: object
      properties:
        node:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.NodeDef'
          title: node
        versions:
          allOf:
            - title: versions
              description: |-
                Compatibility versions of the graph.  See core/public/version.h for version
                 history.  The GraphDef version is distinct from the TensorFlow version, and
                 each release of TensorFlow will support a range of GraphDef versions.
            - $ref: '#/components/schemas/tensorflow.VersionDef'
        version:
          type: integer
          title: version
          format: int32
          description: |-
            Deprecated single version field; use versions above instead.  Since all
             GraphDef changes before "versions" was introduced were forward
             compatible, this field is entirely ignored.
        library:
          allOf:
            - title: library
              description: |-
                "library" provides user-defined functions.

                 Naming:
                   * library.function.name are in a flat namespace.
                     NOTE: We may need to change it to be hierarchical to support
                     different orgs. E.g.,
                     { "/google/nn", { ... }},
                     { "/google/vision", { ... }}
                     { "/org_foo/module_bar", { ... }}
                     map<string, FunctionDefLib> named_lib;
                   * If node[i].op is the name of one function in "library",
                     node[i] is deemed as a function call. Otherwise, node[i].op
                     must be a primitive operation supported by the runtime.


                 Function call semantics:

                   * The callee may start execution as soon as some of its inputs
                     are ready. The caller may want to use Tuple() mechanism to
                     ensure all inputs are ready in the same time.

                   * The consumer of return values may start executing as soon as
                     the return values the consumer depends on are ready.  The
                     consumer may want to use Tuple() mechanism to ensure the
                     consumer does not start until all return values of the callee
                     function are ready.
            - $ref: '#/components/schemas/tensorflow.FunctionDefLibrary'
        debugInfo:
          allOf:
            - title: debug_info
              description: Stack traces for the nodes in this graph.
            - $ref: '#/components/schemas/tensorflow.GraphDebugInfo'
      title: GraphDef
      additionalProperties: false
      description: Represents the graph of operations
    tensorflow.GraphOptions:
      type: object
      properties:
        enableRecvScheduling:
          type: boolean
          title: enable_recv_scheduling
          description: |-
            If true, use control flow to schedule the activation of Recv nodes.
             (Currently ignored.)
        optimizerOptions:
          allOf:
            - title: optimizer_options
              description: Options controlling how graph is optimized.
            - $ref: '#/components/schemas/tensorflow.OptimizerOptions'
        buildCostModel:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: build_cost_model
          description: |-
            The number of steps to run before returning a cost model detailing
             the memory usage and performance of each node of the graph. 0 means
             no cost model.
        buildCostModelAfter:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: build_cost_model_after
          description: |-
            The number of steps to skip before collecting statistics for the
             cost model.
        inferShapes:
          type: boolean
          title: infer_shapes
          description: |-
            Annotate each Node with Op output shape data, to the extent it can
             be statically inferred.
        placePrunedGraph:
          type: boolean
          title: place_pruned_graph
          description: |-
            Only place the subgraphs that are run, rather than the entire graph.

             This is useful for interactive graph building, where one might
             produce graphs that cannot be placed during the debugging
             process.  In particular, it allows the client to continue work in
             a session after adding a node to a graph whose placement
             constraints are unsatisfiable.
        enableBfloat16Sendrecv:
          type: boolean
          title: enable_bfloat16_sendrecv
          description: If true, transfer float values between processes as bfloat16.
        timelineStep:
          type: integer
          title: timeline_step
          format: int32
          description: |-
            If > 0, record a timeline every this many steps.
             EXPERIMENTAL: This currently has no effect in MasterSession.
        rewriteOptions:
          allOf:
            - title: rewrite_options
              description: |-
                Options that control the type and amount of graph rewriting.
                 Not currently configurable via the public Python API (i.e. there is no API
                 stability guarantee if you import RewriterConfig explicitly).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig'
      title: GraphOptions
      additionalProperties: false
    tensorflow.InterconnectLink:
      type: object
      properties:
        deviceId:
          type: integer
          title: device_id
          format: int32
        type:
          type: string
          title: type
        strength:
          type: integer
          title: strength
          format: int32
      title: InterconnectLink
      additionalProperties: false
    tensorflow.JobDef:
      type: object
      properties:
        name:
          type: string
          title: name
          description: The name of this job.
        tasks:
          type: object
          title: tasks
          additionalProperties:
            type: string
            title: value
          description: |-
            Mapping from task ID to "hostname:port" string.

             If the `name` field contains "worker", and the `tasks` map contains a
             mapping from 7 to "example.org:2222", then the device prefix
             "/job:worker/task:7" will be assigned to "example.org:2222".

             If a job has multiple replicas, host-ports will be comma-delimited, with
             one entry for each replica.
      title: JobDef
      additionalProperties: false
      description: Defines a single job in a TensorFlow cluster.
    tensorflow.JobDef.TasksEntry:
      type: object
      properties:
        key:
          type: integer
          title: key
          format: int32
        value:
          type: string
          title: value
      title: TasksEntry
      additionalProperties: false
    tensorflow.ListDevicesRequest:
      type: object
      properties:
        sessionHandle:
          type: string
          title: session_handle
          description: |-
            Optional: session_handle must be returned by a CreateSession call to the
             same master service.

             When session_handle is empty, the ClusterSpec provided when the master was
             started is used to compute the available devices. If the session_handle is
             provided but not recognized, an error is returned. Finally, if a valid
             session_handle is provided, the cluster configuration for that session is
             used when computing the response.
      title: ListDevicesRequest
      additionalProperties: false
    tensorflow.ListDevicesResponse:
      type: object
      properties:
        localDevice:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.DeviceAttributes'
          title: local_device
        remoteDevice:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.DeviceAttributes'
          title: remote_device
      title: ListDevicesResponse
      additionalProperties: false
    tensorflow.LocalLinks:
      type: object
      properties:
        link:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.InterconnectLink'
          title: link
      title: LocalLinks
      additionalProperties: false
    tensorflow.MakeCallableRequest:
      type: object
      properties:
        sessionHandle:
          type: string
          title: session_handle
          description: |-
            REQUIRED: session_handle must be returned by a CreateSession call
             to the same master service.
        options:
          allOf:
            - title: options
              description: Options that define the behavior of the created callable.
            - $ref: '#/components/schemas/tensorflow.CallableOptions'
        requestId:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: request_id
          description: |-
            Unique identifier for this request. Every MakeCallableRequest must
             have a unique request_id, and retried MakeCallableRequest must have
             the same request_id. If request_id is zero, retry detection is disabled.
      title: MakeCallableRequest
      additionalProperties: false
    tensorflow.MakeCallableResponse:
      type: object
      properties:
        handle:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: handle
          description: A handle to the created callable.
      title: MakeCallableResponse
      additionalProperties: false
    tensorflow.MemoryStats:
      type: object
      properties:
        tempMemorySize:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: temp_memory_size
        persistentMemorySize:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: persistent_memory_size
        persistentTensorAllocIds:
          type: array
          items:
            oneOf:
              - type: string
              - type: integer
                format: int64
          title: persistent_tensor_alloc_ids
        deviceTempMemorySize:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: device_temp_memory_size
        devicePersistentMemorySize:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: device_persistent_memory_size
        devicePersistentTensorAllocIds:
          type: array
          items:
            oneOf:
              - type: string
              - type: integer
                format: int64
          title: device_persistent_tensor_alloc_ids
      title: MemoryStats
      additionalProperties: false
      description: For memory tracking.
    tensorflow.NameAttrList:
      type: object
      properties:
        name:
          type: string
          title: name
        attr:
          type: object
          title: attr
          additionalProperties:
            allOf:
              - title: value
              - $ref: '#/components/schemas/tensorflow.AttrValue'
      title: NameAttrList
      additionalProperties: false
      description: |-
        A list of attr names and their values. The whole list is attached
         with a string name.  E.g., MatMul[T=float].
    tensorflow.NameAttrList.AttrEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          allOf:
            - title: value
            - $ref: '#/components/schemas/tensorflow.AttrValue'
      title: AttrEntry
      additionalProperties: false
    tensorflow.NamedTensorProto:
      type: object
      properties:
        name:
          type: string
          title: name
          description: Name of the tensor.
        tensor:
          allOf:
            - title: tensor
              description: |-
                The client can populate a TensorProto using a tensorflow::Tensor`, or
                 directly using the protobuf field accessors.

                 The client specifies whether the returned tensor values should be
                 filled tensor fields (float_val, int_val, etc.) or encoded in a
                 compact form in tensor.tensor_content.
            - $ref: '#/components/schemas/tensorflow.TensorProto'
      title: NamedTensorProto
      additionalProperties: false
      description: A pair of tensor name and tensor values.
    tensorflow.NodeDef:
      type: object
      properties:
        name:
          type: string
          title: name
          description: |-
            The name given to this operator. Used for naming inputs,
             logging, visualization, etc.  Unique within a single GraphDef.
             Must match the regexp "[A-Za-z0-9.][A-Za-z0-9_>./]*".
        op:
          type: string
          title: op
          description: |-
            The operation name.  There may be custom parameters in attrs.
             Op names starting with an underscore are reserved for internal use.
        input:
          type: array
          items:
            type: string
          title: input
          description: |-
            Each input is "node:src_output" with "node" being a string name and
             "src_output" indicating which output tensor to use from "node". If
             "src_output" is 0 the ":0" suffix can be omitted.  Regular inputs
             may optionally be followed by control inputs that have the format
             "^node".
        device:
          type: string
          title: device
          description: |-
            A (possibly partial) specification for the device on which this
             node should be placed.
             The expected syntax for this string is as follows:

             DEVICE_SPEC ::= PARTIAL_SPEC

             PARTIAL_SPEC ::= ("/" CONSTRAINT) *
             CONSTRAINT ::= ("job:" JOB_NAME)
                          | ("replica:" [1-9][0-9]*)
                          | ("task:" [1-9][0-9]*)
                          | ("device:" [A-Za-z]* ":" ([1-9][0-9]* | "*") )

             Valid values for this string include:
             * "/job:worker/replica:0/task:1/device:GPU:3"  (full specification)
             * "/job:worker/device:GPU:3"                   (partial specification)
             * ""                                    (no specification)

             If the constraints do not resolve to a single device (or if this
             field is empty or not present), the runtime will attempt to
             choose a device automatically.
        attr:
          type: object
          title: attr
          additionalProperties:
            allOf:
              - title: value
              - $ref: '#/components/schemas/tensorflow.AttrValue'
          description: |-
            Operation-specific graph-construction-time configuration.
             Note that this should include all attrs defined in the
             corresponding OpDef, including those with a value matching
             the default -- this allows the default to change and makes
             NodeDefs easier to interpret on their own.  However, if
             an attr with a default is not specified in this list, the
             default will be used.
             The "names" (keys) must match the regexp "[a-z][a-z0-9_]+" (and
             one of the names from the corresponding OpDef's attr field).
             The values must have a type matching the corresponding OpDef
             attr's type field.
             TODO(josh11b): Add some examples here showing best practices.
        experimentalDebugInfo:
          allOf:
            - title: experimental_debug_info
              description: This stores debug information associated with the node.
            - $ref: '#/components/schemas/tensorflow.NodeDef.ExperimentalDebugInfo'
        experimentalType:
          allOf:
            - title: experimental_type
              description: |-
                The complete type of this node. Experimental and subject to change.
                 Currently, the field only contains the return types of the node. That will
                 extend in the future to contain the entire signature of the node, as a
                 function type.
            - $ref: '#/components/schemas/tensorflow.FullTypeDef'
      title: NodeDef
      additionalProperties: false
    tensorflow.NodeDef.AttrEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          allOf:
            - title: value
            - $ref: '#/components/schemas/tensorflow.AttrValue'
      title: AttrEntry
      additionalProperties: false
    tensorflow.NodeDef.ExperimentalDebugInfo:
      type: object
      properties:
        originalNodeNames:
          type: array
          items:
            type: string
          title: original_node_names
          description: |-
            Opaque string inserted into error messages created by the runtime.

             This is intended to store the list of names of the nodes from the
             original graph that this node was derived. For example if this node, say
             C, was result of a fusion of 2 nodes A and B, then 'original_node' would
             be {A, B}. This information can be used to map errors originating at the
             current node to some top level source code.
        originalFuncNames:
          type: array
          items:
            type: string
          title: original_func_names
          description: |-
            This is intended to store the list of names of the functions from the
             original graph that this node was derived. For example if this node, say
             C, was result of a fusion of node A in function FA and node B in function
             FB, then `original_funcs` would be {FA, FB}. If the node is in the top
             level graph, the `original_func` is empty. This information, with the
             `original_node_names` can be used to map errors originating at the
             current ndoe to some top level source code.
      title: ExperimentalDebugInfo
      additionalProperties: false
    tensorflow.NodeExecStats:
      type: object
      properties:
        nodeName:
          type: string
          title: node_name
          description: |-
            TODO(tucker): Use some more compact form of node identity than
             the full string name.  Either all processes should agree on a
             global id (cost_id?) for each node, or we should use a hash of
             the name.
        allStartMicros:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: all_start_micros
        opStartRelMicros:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: op_start_rel_micros
        opEndRelMicros:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: op_end_rel_micros
        allEndRelMicros:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: all_end_rel_micros
        memory:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.AllocatorMemoryUsed'
          title: memory
        output:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.NodeOutput'
          title: output
        timelineLabel:
          type: string
          title: timeline_label
        scheduledMicros:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: scheduled_micros
        threadId:
          type: integer
          title: thread_id
        referencedTensor:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.AllocationDescription'
          title: referenced_tensor
        memoryStats:
          allOf:
            - title: memory_stats
            - $ref: '#/components/schemas/tensorflow.MemoryStats'
        allStartNanos:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: all_start_nanos
        opStartRelNanos:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: op_start_rel_nanos
        opEndRelNanos:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: op_end_rel_nanos
        allEndRelNanos:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: all_end_rel_nanos
        scheduledNanos:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: scheduled_nanos
      title: NodeExecStats
      additionalProperties: false
      description: Time/size stats recorded for a single execution of a graph node.
    tensorflow.NodeOutput:
      type: object
      properties:
        slot:
          type: integer
          title: slot
          format: int32
        tensorDescription:
          allOf:
            - title: tensor_description
            - $ref: '#/components/schemas/tensorflow.TensorDescription'
      title: NodeOutput
      additionalProperties: false
      description: Output sizes recorded for a single execution of a graph node.
    tensorflow.OpDef:
      type: object
      properties:
        name:
          type: string
          title: name
          description: |-
            Op names starting with an underscore are reserved for internal use.
             Names should be CamelCase and match the regexp "[A-Z][a-zA-Z0-9>_]*".
        inputArg:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.OpDef.ArgDef'
          title: input_arg
          description: Description of the input(s).
        outputArg:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.OpDef.ArgDef'
          title: output_arg
          description: Description of the output(s).
        controlOutput:
          type: array
          items:
            type: string
          title: control_output
          description: |-
            Named control outputs for this operation. Useful only for composite
             operations (i.e. functions) which want to name different control outputs.
        attr:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.OpDef.AttrDef'
          title: attr
        deprecation:
          allOf:
            - title: deprecation
              description: Optional deprecation based on GraphDef versions.
            - $ref: '#/components/schemas/tensorflow.OpDeprecation'
        summary:
          type: string
          title: summary
          description: One-line human-readable description of what the Op does.
        description:
          type: string
          title: description
          description: Additional, longer human-readable description of what the Op does.
        isCommutative:
          type: boolean
          title: is_commutative
          description: True if the operation is commutative ("op(a,b) == op(b,a)" for all inputs)
        isAggregate:
          type: boolean
          title: is_aggregate
          description: |-
            If is_aggregate is true, then this operation accepts N >= 2
             inputs and produces 1 output all of the same type.  Should be
             associative and commutative, and produce output with the same
             shape as the input.  The optimizer may replace an aggregate op
             taking input from multiple devices with a tree of aggregate ops
             that aggregate locally within each device (and possibly within
             groups of nearby devices) before communicating.
             TODO(josh11b): Implement that optimization. for things like add
        isStateful:
          type: boolean
          title: is_stateful
          description: |-
            Ops are marked as stateful if their behavior depends on some state beyond
             their input tensors (e.g. variable reading op) or if they have
             a side-effect (e.g. printing or asserting ops). Equivalently, stateless ops
             must always produce the same output for the same input and have
             no side-effects.

             By default Ops may be moved between devices.  Stateful ops should
             either not be moved, or should only be moved if that state can also
             be moved (e.g. via some sort of save / restore).
             Stateful ops are guaranteed to never be optimized away by Common
             Subexpression Elimination (CSE). for things like variables, queue
        allowsUninitializedInput:
          type: boolean
          title: allows_uninitialized_input
          description: |-
            By default, all inputs to an Op must be initialized Tensors.  Ops
             that may initialize tensors for the first time should set this
             field to true, to allow the Op to take an uninitialized Tensor as
             input. for Assign, etc.
        isDistributedCommunication:
          type: boolean
          title: is_distributed_communication
          description: |-
            Indicates whether the op implementation uses distributed communication.
             If True, the op is allowed to return errors for network disconnection and
             trigger TF network failure handling logics.
      title: OpDef
      additionalProperties: false
      description: |-
        Defines an operation. A NodeDef in a GraphDef specifies an Op by
         using the "op" field which should match the name of a OpDef.
         LINT.IfChange
    tensorflow.OpDef.ArgDef:
      type: object
      properties:
        name:
          type: string
          title: name
          description: Name for the input/output.  Should match the regexp "[a-z][a-z0-9_]*".
        description:
          type: string
          title: description
          description: Human readable description.
        type:
          allOf:
            - title: type
              description: |-
                Describes the type of one or more tensors that are accepted/produced
                 by this input/output arg.  The only legal combinations are:
                 * For a single tensor: either the "type" field is set or the
                   "type_attr" field is set to the name of an attr with type "type".
                 * For a sequence of tensors with the same type: the "number_attr"
                   field will be set to the name of an attr with type "int", and
                   either the "type" or "type_attr" field will be set as for
                   single tensors.
                 * For a sequence of tensors, the "type_list_attr" field will be set
                   to the name of an attr with type "list(type)".
            - $ref: '#/components/schemas/tensorflow.DataType'
        typeAttr:
          type: string
          title: type_attr
          description: if specified, attr must have type "type"
        numberAttr:
          type: string
          title: number_attr
          description: if specified, attr must have type "int"
        typeListAttr:
          type: string
          title: type_list_attr
          description: |-
            If specified, attr must have type "list(type)", and none of
             type, type_attr, and number_attr may be specified.
        handleData:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.ResourceHandleProto.DtypeAndShape'
          title: handle_data
          description: The handle data for resource inputs.
        isRef:
          type: boolean
          title: is_ref
          description: |-
            For inputs: if true, the inputs are required to be refs.
               By default, inputs can be either refs or non-refs.
             For outputs: if true, outputs are refs, otherwise they are not.
        experimentalFullType:
          allOf:
            - title: experimental_full_type
              description: |-
                Experimental. Full type declaration for this argument.
                 The full type specification combines type, type_attr, type_list_attr,
                 etc. into a unified representation.
                 This declaration may contain non-concrete types (for example,
                 Tensor<TypeVar<'T'>> is a valid type declaration.

                 Note: this is a transient field. The long-term aim is to represent the
                 entire OpDef as a single type: a callable. In that context, this field is
                 just the type of a single argument.
            - $ref: '#/components/schemas/tensorflow.FullTypeDef'
      title: ArgDef
      additionalProperties: false
      description: For describing inputs and outputs.
    tensorflow.OpDef.AttrDef:
      type: object
      properties:
        name:
          type: string
          title: name
          description: |-
            A descriptive name for the argument.  May be used, e.g. by the
             Python client, as a keyword argument name, and so should match
             the regexp "[a-z][a-z0-9_]+".
        type:
          type: string
          title: type
          description: |-
            One of the type names from attr_value.proto ("string", "list(string)",
             "int", etc.).
        defaultValue:
          allOf:
            - title: default_value
              description: |-
                A reasonable default for this attribute if the user does not supply
                 a value.  If not specified, the user must supply a value.
            - $ref: '#/components/schemas/tensorflow.AttrValue'
        description:
          type: string
          title: description
          description: Human-readable description.
        hasMinimum:
          type: boolean
          title: has_minimum
          description: |-
            For type == "int", this is a minimum value.  For "list(___)"
             types, this is the minimum length.
        minimum:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: minimum
        allowedValues:
          allOf:
            - title: allowed_values
              description: |-
                The set of allowed values.  Has type that is the "list" version
                 of the "type" field above (uses the "list" field of AttrValue).
                 If type == "type" or "list(type)" above, then the "type" field
                 of "allowed_values.list" has the set of allowed DataTypes.
                 If type == "string" or "list(string)", then the "s" field of
                 "allowed_values.list" has the set of allowed strings.
            - $ref: '#/components/schemas/tensorflow.AttrValue'
      title: AttrDef
      additionalProperties: false
      description: |-
        Description of the graph-construction-time configuration of this
         Op.  That is to say, this describes the attr fields that will
         be specified in the NodeDef.
    tensorflow.OpDeprecation:
      type: object
      properties:
        version:
          type: integer
          title: version
          format: int32
          description: First GraphDef version at which the op is disallowed.
        explanation:
          type: string
          title: explanation
          description: Explanation of why it was deprecated and what to use instead.
      title: OpDeprecation
      additionalProperties: false
      description: Information about version-dependent deprecation of an op
    tensorflow.OptimizerOptions:
      type: object
      properties:
        doCommonSubexpressionElimination:
          type: boolean
          title: do_common_subexpression_elimination
          description: |-
            If true, optimize the graph using common subexpression elimination.
             Note: the optimization Level L1 will override this setting to true. So in
             order to disable common subexpression elimination the opt_level has to be
             set to L0.
        doConstantFolding:
          type: boolean
          title: do_constant_folding
          description: |-
            If true, perform constant folding optimization on the graph.
             Note: the optimization Level L1 will override this setting to true. So in
             order to disable constant folding the opt_level has to be set to L0.
        maxFoldedConstantInBytes:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: max_folded_constant_in_bytes
          description: |-
            Constant folding optimization replaces tensors whose values can be
             predetermined, with constant nodes. To avoid inserting too large constants,
             the size of each constant created can be limited. If this value is zero, a
             default limit of 10 MiB will be applied. If constant folding optimization
             is disabled, this value is ignored.
        doFunctionInlining:
          type: boolean
          title: do_function_inlining
          description: If true, perform function inlining on the graph.
        optLevel:
          allOf:
            - title: opt_level
              description: |-
                Overall optimization level. The actual optimizations applied will be the
                 logical OR of the flags that this level implies and any flags already set.
            - $ref: '#/components/schemas/tensorflow.OptimizerOptions.Level'
        globalJitLevel:
          allOf:
            - title: global_jit_level
            - $ref: '#/components/schemas/tensorflow.OptimizerOptions.GlobalJitLevel'
        cpuGlobalJit:
          type: boolean
          title: cpu_global_jit
          description: |-
            CPU code will be autoclustered only if global_jit_level >= ON_1 and either:
              - this flag is true, or
              - TF_XLA_FLAGS contains --tf_xla_cpu_global_jit=true.
      title: OptimizerOptions
      additionalProperties: false
      description: Options passed to the graph optimizer
    tensorflow.PartialRunSetupRequest:
      type: object
      properties:
        sessionHandle:
          type: string
          title: session_handle
          description: |-
            REQUIRED: session_handle must be returned by a CreateSession call
             to the same master service.
        feed:
          type: array
          items:
            type: string
          title: feed
          description: Tensors to be fed in future steps.
        fetch:
          type: array
          items:
            type: string
          title: fetch
          description: |-
            Fetches. A list of tensor names. The caller expects a tensor to be returned
             for each fetch[i] (see RunStepResponse.tensor), for corresponding partial
             RunStepRequests. The order of specified fetches does not change the
             execution order.
        target:
          type: array
          items:
            type: string
          title: target
          description: |-
            Target Nodes. A list of node names. The named nodes will be run in future
             steps, but their outputs will not be fetched.
        requestId:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: request_id
          description: |-
            Unique identifier for this request. Every PartialRunSetupRequest must
             have a unique request_id, and retried PartialRunSetupRequest must have
             the same request_id. If request_id is zero, retry detection is disabled.
      title: PartialRunSetupRequest
      additionalProperties: false
    tensorflow.PartialRunSetupResponse:
      type: object
      properties:
        partialRunHandle:
          type: string
          title: partial_run_handle
          description: |-
            The unique handle corresponding to the ongoing partial run call setup by
             the invocation to PartialRunSetup. This handle may be passed to
             RunStepRequest to send and receive tensors for this partial run.
      title: PartialRunSetupResponse
      additionalProperties: false
    tensorflow.RPCOptions:
      type: object
      properties:
        useRpcForInprocessMaster:
          type: boolean
          title: use_rpc_for_inprocess_master
          description: |-
            If true, always use RPC to contact the session target.

             If false (the default option), TensorFlow may use an optimized
             transport for client-master communication that avoids the RPC
             stack. This option is primarily for used testing the RPC stack.
        compressionAlgorithm:
          type: string
          title: compression_algorithm
          description: The compression algorithm to be used. One of "deflate", "gzip".
        compressionLevel:
          type: integer
          title: compression_level
          format: int32
          description: |-
            If compression_algorithm is set, the compression level to be used.
             From 0 (no compression), up to 3.
        cacheRpcResponse:
          type: boolean
          title: cache_rpc_response
          description: |-
            Setting cache_rpc_response to true will enable sender side caching of
             response for RecvTensorAsync and RecvBufAsync to allow receiver to retry
             requests . This is only necessary when the network fabric is experiencing a
             significant error rate.  Without it we'll fail a step on an network error,
             while with it we'll be able to complete long steps (like complex
             initializations) in the face of some network errors during RecvTensor.
        disableSessionConnectionSharing:
          type: boolean
          title: disable_session_connection_sharing
          description: Disables TCP connection sharing when opening a new RPC channel.
        numChannelsPerTarget:
          type: integer
          title: num_channels_per_target
          format: int32
          description: |-
            Setting num_channels_per_target > 0 allows uses of multiple channels to
             communicate to the same target. This can be used to improve the aggregate
             throughput on high speed links (e.g 100G) where single connection is not
             sufficient to maximize link utilization. Note that a single RPC only goes
             on a single channel, this only helps in situations where there are multiple
             transfers to the same target overlapping in time.
      title: RPCOptions
      additionalProperties: false
      description: RPC options for distributed runtime.
    tensorflow.RegisteredGradient:
      type: object
      properties:
        gradientFunc:
          type: string
          title: gradient_func
          description: The gradient function's name.
        registeredOpType:
          type: string
          title: registered_op_type
          description: The gradient function's registered op type.
      title: RegisteredGradient
      additionalProperties: false
      description: |-
        RegisteredGradient stores a gradient function that is registered in the
         gradients library and used in the ops of a function in the function library.
         Unlike GradientDef, these gradients are identified by op type, and not
         directly linked to any function.
    tensorflow.ReleaseCallableRequest:
      type: object
      properties:
        sessionHandle:
          type: string
          title: session_handle
          description: |-
            REQUIRED: session_handle must be returned by a CreateSession call
             to the same master service.
        handle:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: handle
          description: |-
            REQUIRED: handle must be returned by a MakeCallable call to the same
             master service.
      title: ReleaseCallableRequest
      additionalProperties: false
    tensorflow.ReleaseCallableResponse:
      type: object
      title: ReleaseCallableResponse
      additionalProperties: false
    tensorflow.ResetRequest:
      type: object
      properties:
        container:
          type: array
          items:
            type: string
          title: container
          description: |-
            A list of container names, which may be empty.

             If 'container' is not empty, releases resources in the given
             containers in all devices.

             If 'container' is empty, releases resources in the default
             container in all devices.
        deviceFilters:
          type: array
          items:
            type: string
          title: device_filters
          description: |-
            When any filters are present, only devices that match the filters
             will be reset. Each filter can be partially specified,
             e.g. "/job:ps" "/job:worker/replica:3", etc.
      title: ResetRequest
      additionalProperties: false
      description: |-
        Reset() allows misbehaving or slow sessions to be aborted and closed, and
         causes their resources eventually to be released.  Reset() does not wait
         for the computations in old sessions to cease; it merely starts the
         process of tearing them down.  However, if a new session is started after
         a Reset(), the new session is isolated from changes that old sessions
         (started prior to the Reset()) may continue to make to resources, provided
         all those resources are in containers listed in "containers".

         Old sessions may continue to have side-effects on resources not in
         containers listed in "containers", and thus may affect future
         sessions' results in ways that are hard to predict.  Thus, if well-defined
         behavior is desired, is it recommended that all containers be listed in
         "containers".  Similarly, if a device_filter is specified, results may be
         hard to predict.
    tensorflow.ResetResponse:
      type: object
      title: ResetResponse
      additionalProperties: false
    tensorflow.ResourceHandleProto:
      type: object
      properties:
        device:
          type: string
          title: device
          description: Unique name for the device containing the resource.
        container:
          type: string
          title: container
          description: Container in which this resource is placed.
        name:
          type: string
          title: name
          description: Unique name of this resource.
        hashCode:
          oneOf:
            - type: string
            - type: integer
          title: hash_code
          description: |-
            Hash code for the type of the resource. Is only valid in the same device
             and in the same execution.
        maybeTypeName:
          type: string
          title: maybe_type_name
          description: |-
            For debug-only, the name of the type pointed to by this handle, if
             available.
        dtypesAndShapes:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.ResourceHandleProto.DtypeAndShape'
          title: dtypes_and_shapes
          description: Data types and shapes for the underlying resource.
      title: ResourceHandleProto
      additionalProperties: false
      description: |-
        Protocol buffer representing a handle to a tensorflow resource. Handles are
         not valid across executions, but can be serialized back and forth from within
         a single run.
    tensorflow.ResourceHandleProto.DtypeAndShape:
      type: object
      properties:
        dtype:
          allOf:
            - title: dtype
            - $ref: '#/components/schemas/tensorflow.DataType'
        shape:
          allOf:
            - title: shape
            - $ref: '#/components/schemas/tensorflow.TensorShapeProto'
      title: DtypeAndShape
      additionalProperties: false
      description: Protocol buffer representing a pair of (data type, tensor shape).
    tensorflow.RewriterConfig:
      type: object
      properties:
        cpuLayoutConversion:
          allOf:
            - title: cpu_layout_conversion
              description: CPU Conversion settings between NHCW and NCHW.
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.CpuLayout'
        layoutOptimizer:
          allOf:
            - title: layout_optimizer
              description: |-
                Optimize tensor layouts (default is ON)
                 e.g. This will try to use NCHW layout on GPU which is faster.
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        constantFolding:
          allOf:
            - title: constant_folding
              description: |-
                Fold constants (default is ON)
                 Statically infer the value of tensors when possible, and materialize the
                 result using constants.
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        shapeOptimization:
          allOf:
            - title: shape_optimization
              description: |-
                Shape optimizations (default is ON)
                 Simplify computations made on shapes.
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        remapping:
          allOf:
            - title: remapping
              description: |-
                Remapping (default is ON)
                 Remap subgraphs onto more efficient implementations.
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        commonSubgraphElimination:
          allOf:
            - title: common_subgraph_elimination
              description: |-
                Common subgraph elimination (default is ON)
                 e.g. Simplify arithmetic ops; merge ops with same value (like constants).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        arithmeticOptimization:
          allOf:
            - title: arithmetic_optimization
              description: |-
                Arithmetic optimizations (default is ON)
                 e.g. Simplify arithmetic ops; merge ops with same value (like constants).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        dependencyOptimization:
          allOf:
            - title: dependency_optimization
              description: |-
                Control dependency optimizations (default is ON).
                 Remove redundant control dependencies, which may enable other optimization.
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        loopOptimization:
          allOf:
            - title: loop_optimization
              description: Loop optimizations (default is ON).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        functionOptimization:
          allOf:
            - title: function_optimization
              description: Function optimizations (default is ON).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        debugStripper:
          allOf:
            - title: debug_stripper
              description: Strips debug-related nodes from the graph (off by default).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        disableModelPruning:
          type: boolean
          title: disable_model_pruning
          description: If true, don't remove unnecessary ops from the graph
        scopedAllocatorOptimization:
          allOf:
            - title: scoped_allocator_optimization
              description: |-
                Try to allocate some independent Op outputs contiguously in order to
                 merge or eliminate downstream Ops (off by default).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        pinToHostOptimization:
          allOf:
            - title: pin_to_host_optimization
              description: Force small ops onto the CPU (default is OFF).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        implementationSelector:
          allOf:
            - title: implementation_selector
              description: |-
                Enable the swap of kernel implementations based on the device placement
                 (default is ON).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        autoMixedPrecision:
          allOf:
            - title: auto_mixed_precision
              description: |-
                Optimize data types for CUDA (default is OFF).
                 This will try to use float16 on GPU which is faster.
                 Note that this can change the numerical stability of the graph and may
                 require the use of loss scaling to maintain model convergence.
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        autoMixedPrecisionMkl:
          allOf:
            - title: auto_mixed_precision_mkl
              description: |-
                Optimize data types for oneDNN (default is OFF).
                 This will try to use bfloat16 on CPUs, which is faster.
                 Note that this can change the numerical stability of the graph.
                 Note: this is deprecated.
                 It is replaced by auto_mixed_precision_onednn_bfloat16
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        autoMixedPrecisionOnednnBfloat16:
          allOf:
            - title: auto_mixed_precision_onednn_bfloat16
              description: |-
                Optimize data types for oneDNN (default is OFF).
                 This will try to use bfloat16 on CPUs, which is faster.
                 Note that this can change the numerical stability of the graph.
                 Note: this is equivalent to the deprecated option auto_mixed_precision_mkl
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        autoMixedPrecisionCpu:
          allOf:
            - title: auto_mixed_precision_cpu
              description: |-
                Emulate a model using data type float16 on CPU (default is OFF).
                 This will try to emulate the float16 inputs and outputs of an operator
                 on CPU to have better correlation with float16 on GPU; however the
                 computation in the operator is based on float32.
                 Note that this can change the numerical stability of the graph.
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        disableMetaOptimizer:
          type: boolean
          title: disable_meta_optimizer
          description: Disable the entire meta optimizer (off by default).
        disableTfgOptimizer:
          type: boolean
          title: disable_tfg_optimizer
          description: Disable the TFG optimizer (off by default).
        usePluginOptimizers:
          allOf:
            - title: use_plugin_optimizers
              description: Optimizers registered by plugin (default is ON)
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        experimentalConditionalCodeMotion:
          allOf:
            - title: experimental_conditional_code_motion
              description: Conditional code motion (default is ON).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.Toggle'
        metaOptimizerIterations:
          allOf:
            - title: meta_optimizer_iterations
              description: |-
                Controls how many times we run the optimizers in meta optimizer (default
                 is once).
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.NumIterationsType'
        minGraphNodes:
          type: integer
          title: min_graph_nodes
          format: int32
          description: |-
            The minimum number of nodes in a graph to optimizer. For smaller graphs,
             optimization is skipped.
             0 means the system picks an appropriate number.
             < 0 means do not skip optimization.
        experimentalDisableCompressedTensorOptimization:
          type: boolean
          title: experimental_disable_compressed_tensor_optimization
          description: |-
            Disable optimizations that assume compressed tensors. Note that this flag
             is experimental and may be removed in the future.
        experimentalDisableFoldingQuantizationEmulation:
          type: boolean
          title: experimental_disable_folding_quantization_emulation
          description: |-
            Disable folding quantization emulation ops such as FakeQuantWithMinMax* and
             QuantizeAndDequantize*. Some compilers (e.g. the TF-to-tflite converter)
             have to extract quantization configs (e.g. min/max range, number of bits,
             and per-channel) from the quantization emulation ops. Note that this flag
             is experimental and may be removed in the future. See b/174138564 for more
             details.
        memoryOptimization:
          allOf:
            - title: memory_optimization
              description: |-
                Configures memory optimization passes through the meta-optimizer. Has no
                 effect on manually requested memory optimization passes in the optimizers
                 field.
            - $ref: '#/components/schemas/tensorflow.RewriterConfig.MemOptType'
        memoryOptimizerTargetNodeNameScope:
          type: string
          title: memory_optimizer_target_node_name_scope
          description: |-
            A node name scope for node names which are valid outputs of recomputations.
             Inputs to nodes that match this scope may be recomputed (subject either to
             manual annotation of those input nodes or to manual annotation and
             heuristics depending on memory_optimization), but the nodes themselves will
             not be recomputed. This matches any sub-scopes as well, meaning the scope
             can appear not just as a top-level scope. For example, if the value is
             "gradients/", the default, it will match node name "gradients/foo",
             "foo/gradients/bar", but not "foo_gradients/"
        metaOptimizerTimeoutMs:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: meta_optimizer_timeout_ms
          description: |-
            Maximum number of milliseconds to spend optimizing a single graph before
             timing out. If less than or equal to 0 (default value) the optimizer will
             never time out.
        autoParallel:
          allOf:
            - title: auto_parallel
              description: |-
                Configures AutoParallel optimization passes either through the
                 meta-optimizer or when manually specified through the optimizers field.
            - $ref: '#/components/schemas/tensorflow.AutoParallelOptions'
        failOnOptimizerErrors:
          type: boolean
          title: fail_on_optimizer_errors
          description: |-
            If true, any optimization pass failing will cause the MetaOptimizer to
             stop with an error. By default - or when set to false, failing passes are
             skipped silently.
        scopedAllocatorOpts:
          allOf:
            - title: scoped_allocator_opts
            - $ref: '#/components/schemas/tensorflow.ScopedAllocatorOptions'
        optimizers:
          type: array
          items:
            type: string
          title: optimizers
          description: |-
            If non-empty, will use this as an alternative way to specify a list of
             optimizations to turn on and the order of the optimizations (replacing the
             meta-optimizer).

             Of the RewriterConfig options, only the AutoParallel configuration options
             (the auto_parallel field) apply to manually requested optimization passes
             ("autoparallel"). Memory optimization passes ("memory") invoked here are
             not configurable (in contrast to memory optimization passes through the
             meta-optimizer) and act only on manual op annotations.

             Custom optimizers (see custom_optimizers) that are not part of this
             schedule will be run after - in the order that they were specified.
        customOptimizers:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.RewriterConfig.CustomGraphOptimizer'
          title: custom_optimizers
          description: list of CustomGraphOptimizers to apply.
        interOptimizerVerifierConfig:
          allOf:
            - title: inter_optimizer_verifier_config
              description: VerifierConfig specifying the verifiers to be run after every optimizer.
            - $ref: '#/components/schemas/tensorflow.VerifierConfig'
        postOptimizationVerifierConfig:
          allOf:
            - title: post_optimization_verifier_config
              description: |-
                VerifierConfig specifying the verifiers to be run at the end, after all
                 optimizers have run.
            - $ref: '#/components/schemas/tensorflow.VerifierConfig'
      title: RewriterConfig
      additionalProperties: false
      description: |-
        Graph rewriting is experimental and subject to change, not covered by any
         API stability guarantees.
    tensorflow.RewriterConfig.CustomGraphOptimizer:
      type: object
      properties:
        name:
          type: string
          title: name
        parameterMap:
          type: object
          title: parameter_map
          additionalProperties:
            allOf:
              - title: value
              - $ref: '#/components/schemas/tensorflow.AttrValue'
      title: CustomGraphOptimizer
      additionalProperties: false
      description: Message to describe custom graph optimizer and its parameters
    tensorflow.RewriterConfig.CustomGraphOptimizer.ParameterMapEntry:
      type: object
      properties:
        key:
          type: string
          title: key
        value:
          allOf:
            - title: value
            - $ref: '#/components/schemas/tensorflow.AttrValue'
      title: ParameterMapEntry
      additionalProperties: false
    tensorflow.RunCallableRequest:
      type: object
      properties:
        sessionHandle:
          type: string
          title: session_handle
          description: |-
            REQUIRED: session_handle must be returned by a CreateSession call
             to the same master service.
        handle:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: handle
          description: |-
            REQUIRED: handle must be returned by a MakeCallable call to the same
             master service.
        feed:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.TensorProto'
          title: feed
          description: |-
            Values of the tensors passed as arguments to the callable, in the order
             defined in the CallableOptions.feed field passed to MakeCallable.
        requestId:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: request_id
          description: |-
            Unique identifier for this request. Every RunCallableRequest must
             have a unique request_id, and retried RunCallableRequest must have
             the same request_id. If request_id is zero, retry detection is disabled.
      title: RunCallableRequest
      additionalProperties: false
    tensorflow.RunCallableResponse:
      type: object
      properties:
        fetch:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.TensorProto'
          title: fetch
          description: |-
            Values of the tensors returned by the callable, in the order defined in the
             CallableOptions.fetch field passed to MakeCallable.
        metadata:
          allOf:
            - title: metadata
              description: Returned metadata if requested in the options.
            - $ref: '#/components/schemas/tensorflow.RunMetadata'
      title: RunCallableResponse
      additionalProperties: false
    tensorflow.RunMetadata:
      type: object
      properties:
        stepStats:
          allOf:
            - title: step_stats
              description: |-
                Statistics traced for this step. Populated if tracing is turned on via the
                 "RunOptions" proto.
                 EXPERIMENTAL: The format and set of events may change in future versions.
            - $ref: '#/components/schemas/tensorflow.StepStats'
        costGraph:
          allOf:
            - title: cost_graph
              description: The cost graph for the computation defined by the run call.
            - $ref: '#/components/schemas/tensorflow.CostGraphDef'
        partitionGraphs:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.GraphDef'
          title: partition_graphs
          description: Graphs of the partitions executed by executors.
        functionGraphs:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.RunMetadata.FunctionGraphs'
          title: function_graphs
          description: |-
            This is only populated for graphs that are run as functions in TensorFlow
             V2. There will be an entry below for each function that is traced.
             The main use cases of the post_optimization_graph and the partition_graphs
             is to give the caller insight into the graphs that were actually run by the
             runtime. Additional information (such as those in step_stats) will match
             these graphs.
             We also include the pre_optimization_graph since it is usually easier to
             read, and is helpful in situations where the caller wants to get a high
             level idea of what the built graph looks like (since the various graph
             optimization passes might change the structure of the graph significantly).
        sessionMetadata:
          allOf:
            - title: session_metadata
              description: Metadata about the session.
            - $ref: '#/components/schemas/tensorflow.SessionMetadata'
      title: RunMetadata
      additionalProperties: false
      description: Metadata output (i.e., non-Tensor) for a single Run() call.
    tensorflow.RunMetadata.FunctionGraphs:
      type: object
      properties:
        partitionGraphs:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.GraphDef'
          title: partition_graphs
          description: 'TODO(nareshmodi): Include some sort of function/cache-key identifier?'
        preOptimizationGraph:
          allOf:
            - title: pre_optimization_graph
            - $ref: '#/components/schemas/tensorflow.GraphDef'
        postOptimizationGraph:
          allOf:
            - title: post_optimization_graph
            - $ref: '#/components/schemas/tensorflow.GraphDef'
      title: FunctionGraphs
      additionalProperties: false
    tensorflow.RunOptions:
      type: object
      properties:
        traceLevel:
          allOf:
            - title: trace_level
            - $ref: '#/components/schemas/tensorflow.RunOptions.TraceLevel'
        timeoutInMs:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: timeout_in_ms
          description: Time to wait for operation to complete in milliseconds.
        interOpThreadPool:
          type: integer
          title: inter_op_thread_pool
          format: int32
          description: |-
            The thread pool to use, if session_inter_op_thread_pool is configured.
             To use the caller thread set this to -1 - this uses the caller thread
             to execute Session::Run() and thus avoids a context switch. Using the
             caller thread to execute Session::Run() should be done ONLY for simple
             graphs, where the overhead of an additional context switch is
             comparable with the overhead of Session::Run().
        outputPartitionGraphs:
          type: boolean
          title: output_partition_graphs
          description: |-
            Whether the partition graph(s) executed by the executor(s) should be
             outputted via RunMetadata.
        debugOptions:
          allOf:
            - title: debug_options
              description: EXPERIMENTAL.  Options used to initialize DebuggerState, if enabled.
            - $ref: '#/components/schemas/tensorflow.DebugOptions'
        reportTensorAllocationsUponOom:
          type: boolean
          title: report_tensor_allocations_upon_oom
          description: |-
            When enabled, causes tensor allocation information to be included in
             the error message when the Run() call fails because the allocator ran
             out of memory (OOM).

             Enabling this option can slow down the Run() call.
        experimental:
          allOf:
            - title: experimental
            - $ref: '#/components/schemas/tensorflow.RunOptions.Experimental'
      title: RunOptions
      additionalProperties: false
      description: Options for a single Run() call.
    tensorflow.RunOptions.Experimental:
      type: object
      properties:
        collectiveGraphKey:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: collective_graph_key
          description: |-
            If non-zero, declares that this graph is going to use collective
             ops and must synchronize step_ids with any other graph with this
             same group_key value (in a distributed computation where tasks
             run disjoint graphs).
        useRunHandlerPool:
          type: boolean
          title: use_run_handler_pool
          description: |-
            If true, then operations (using the inter-op pool) across all
             session::run() calls will be centrally scheduled, optimizing for (median
             and tail) latency.
             Consider using this option for CPU-bound workloads like inference.
        runHandlerPoolOptions:
          allOf:
            - title: run_handler_pool_options
            - $ref: '#/components/schemas/tensorflow.RunOptions.Experimental.RunHandlerPoolOptions'
      title: Experimental
      additionalProperties: false
      description: |-
        Everything inside Experimental is subject to change and is not subject
         to API stability guarantees in
         https://www.tensorflow.org/guide/version_compat.
    tensorflow.RunOptions.Experimental.RunHandlerPoolOptions:
      type: object
      properties:
        priority:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: priority
          description: |-
            Priority of the request. The run handler thread pool will schedule ops
             based on the priority number. The larger number means higher priority.
      title: RunHandlerPoolOptions
      additionalProperties: false
      description: Options for run handler thread pool.
    tensorflow.RunStepRequest:
      type: object
      properties:
        sessionHandle:
          type: string
          title: session_handle
          description: |-
            REQUIRED: session_handle must be returned by a CreateSession call
             to the same master service.
        feed:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.NamedTensorProto'
          title: feed
          description: Tensors to be fed in the step. Each feed is a named tensor.
        fetch:
          type: array
          items:
            type: string
          title: fetch
          description: |-
            Fetches. A list of tensor names. The caller expects a tensor to
             be returned for each fetch[i] (see RunStepResponse.tensor). The
             order of specified fetches does not change the execution order.
        target:
          type: array
          items:
            type: string
          title: target
          description: |-
            Target Nodes. A list of node names. The named nodes will be run
             to but their outputs will not be fetched.
        options:
          allOf:
            - title: options
              description: Options for the run call.
            - $ref: '#/components/schemas/tensorflow.RunOptions'
        partialRunHandle:
          type: string
          title: partial_run_handle
          description: |-
            Partial run handle (optional). If specified, this will be a partial run
             execution, run up to the specified fetches.
        storeErrorsInResponseBody:
          type: boolean
          title: store_errors_in_response_body
          description: |-
            If true then some errors, e.g., execution errors that have long
             error messages, may return an OK RunStepResponse with the actual
             error saved in the status_code/status_error_message fields of the
             response body. This is a workaround since the RPC subsystem may
             truncate long metadata messages.
        requestId:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: request_id
          description: |-
            Unique identifier for this request. Every RunStepRequest must
             have a unique request_id, and retried RunStepRequest must have
             the same request_id. If request_id is zero, retry detection is disabled.
      title: RunStepRequest
      additionalProperties: false
    tensorflow.RunStepResponse:
      type: object
      properties:
        tensor:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.NamedTensorProto'
          title: tensor
          description: |-
            NOTE: The order of the returned tensors may or may not match
             the fetch order specified in RunStepRequest.
        metadata:
          allOf:
            - title: metadata
              description: Returned metadata if requested in the options.
            - $ref: '#/components/schemas/tensorflow.RunMetadata'
        statusCode:
          allOf:
            - title: status_code
              description: |-
                If store_errors_in_response_body is true in the request, then
                 optionally the server may return an OK status for the RPC and
                 fill the true status into the fields below, to allow for messages
                 that are too long to fit in metadata.
            - $ref: '#/components/schemas/tensorflow.error.Code'
        statusErrorMessage:
          type: string
          title: status_error_message
      title: RunStepResponse
      additionalProperties: false
    tensorflow.ScopedAllocatorOptions:
      type: object
      properties:
        enableOp:
          type: array
          items:
            type: string
          title: enable_op
          description: If present, only perform optimization for these ops.
      title: ScopedAllocatorOptions
      additionalProperties: false
    tensorflow.SessionMetadata:
      type: object
      properties:
        name:
          type: string
          title: name
        version:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: version
          description: The version is optional. If set, needs to be >= 0.
      title: SessionMetadata
      additionalProperties: false
      description: |-
        Metadata about the session.

         This can be used by the runtime and the Ops for debugging, monitoring, etc.

         The (name, version) tuple is expected to be a unique identifier for
         sessions within the same process.

         NOTE: This is currently used and propagated only by the direct session.
    tensorflow.StepStats:
      type: object
      properties:
        devStats:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.DeviceStepStats'
          title: dev_stats
      title: StepStats
      additionalProperties: false
    tensorflow.TensorConnection:
      type: object
      properties:
        fromTensor:
          type: string
          title: from_tensor
          description: |-
            A tensor name. The value of this tensor will be substituted for
             the tensor named in `to_tensor`.
        toTensor:
          type: string
          title: to_tensor
          description: |-
            A tensor name. The value of this tensor will be bound to the
             value of the tensor named in `from_tensor`.
      title: TensorConnection
      additionalProperties: false
      description: Defines a connection between two tensors in a `GraphDef`.
    tensorflow.TensorDescription:
      type: object
      properties:
        dtype:
          allOf:
            - title: dtype
              description: Data type of tensor elements
            - $ref: '#/components/schemas/tensorflow.DataType'
        shape:
          allOf:
            - title: shape
              description: Shape of the tensor.
            - $ref: '#/components/schemas/tensorflow.TensorShapeProto'
        allocationDescription:
          allOf:
            - title: allocation_description
              description: Information about the size and allocator used for the data
            - $ref: '#/components/schemas/tensorflow.AllocationDescription'
      title: TensorDescription
      additionalProperties: false
    tensorflow.TensorProto:
      type: object
      properties:
        dtype:
          allOf:
            - title: dtype
            - $ref: '#/components/schemas/tensorflow.DataType'
        tensorShape:
          allOf:
            - title: tensor_shape
              description: 'Shape of the tensor.  TODO(touts): sort out the 0-rank issues.'
            - $ref: '#/components/schemas/tensorflow.TensorShapeProto'
        versionNumber:
          type: integer
          title: version_number
          format: int32
          description: |-
            Version number.

             In version 0, if the "repeated xxx" representations contain only one
             element, that element is repeated to fill the shape.  This makes it easy
             to represent a constant Tensor with a single value.
        tensorContent:
          type: string
          title: tensor_content
          format: byte
          description: |-
            Serialized raw tensor content from either Tensor::AsProtoTensorContent or
             memcpy in tensorflow::grpc::EncodeTensorToByteBuffer. This representation
             can be used for all tensor types. The purpose of this representation is to
             reduce serialization overhead during RPC call by avoiding serialization of
             many repeated small items.
        halfVal:
          type: array
          items:
            type: integer
            format: int32
          title: half_val
          description: |-
            DT_HALF, DT_BFLOAT16. Note that since protobuf has no int16 type, we'll
             have some pointless zero padding for each value here.
        floatVal:
          type: array
          items:
            type: number
            format: float
          title: float_val
          description: DT_FLOAT.
        doubleVal:
          type: array
          items:
            type: number
            format: double
          title: double_val
          description: DT_DOUBLE.
        intVal:
          type: array
          items:
            type: integer
            format: int32
          title: int_val
          description: DT_INT32, DT_INT16, DT_UINT16, DT_INT8, DT_UINT8.
        stringVal:
          type: array
          items:
            type: string
            format: byte
          title: string_val
          description: DT_STRING
        scomplexVal:
          type: array
          items:
            type: number
            format: float
          title: scomplex_val
          description: |-
            DT_COMPLEX64. scomplex_val(2*i) and scomplex_val(2*i+1) are real
             and imaginary parts of i-th single precision complex.
        int64Val:
          type: array
          items:
            oneOf:
              - type: string
              - type: integer
                format: int64
          title: int64_val
          description: DT_INT64
        boolVal:
          type: array
          items:
            type: boolean
          title: bool_val
          description: DT_BOOL
        dcomplexVal:
          type: array
          items:
            type: number
            format: double
          title: dcomplex_val
          description: |-
            DT_COMPLEX128. dcomplex_val(2*i) and dcomplex_val(2*i+1) are real
             and imaginary parts of i-th double precision complex.
        resourceHandleVal:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.ResourceHandleProto'
          title: resource_handle_val
          description: DT_RESOURCE
        variantVal:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.VariantTensorDataProto'
          title: variant_val
          description: DT_VARIANT
        uint32Val:
          type: array
          items:
            type: integer
          title: uint32_val
          description: DT_UINT32
        uint64Val:
          type: array
          items:
            oneOf:
              - type: string
              - type: integer
          title: uint64_val
          description: DT_UINT64
        float8Val:
          type: string
          title: float8_val
          format: byte
          description: |-
            DT_FLOAT8_*, use variable-sized set of bytes
             (i.e. the equivalent of repeated uint8, if such a thing existed).
      title: TensorProto
      additionalProperties: false
      description: Protocol buffer representing a tensor.
    tensorflow.TensorShapeProto:
      type: object
      properties:
        dim:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.TensorShapeProto.Dim'
          title: dim
          description: |-
            Dimensions of the tensor, such as {"input", 30}, {"output", 40}
             for a 30 x 40 2D tensor.  If an entry has size -1, this
             corresponds to a dimension of unknown size. The names are
             optional.

             The order of entries in "dim" matters: It indicates the layout of the
             values in the tensor in-memory representation.

             The first entry in "dim" is the outermost dimension used to layout the
             values, the last entry is the innermost dimension.  This matches the
             in-memory layout of RowMajor Eigen tensors.

             If "dim.size()" > 0, "unknown_rank" must be false.
        unknownRank:
          type: boolean
          title: unknown_rank
          description: |-
            If true, the number of dimensions in the shape is unknown.

             If true, "dim.size()" must be 0.
      title: TensorShapeProto
      additionalProperties: false
      description: Dimensions of a tensor.
    tensorflow.TensorShapeProto.Dim:
      type: object
      properties:
        size:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: size
          description: |-
            Size of the tensor in that dimension.
             This value must be >= -1, but values of -1 are reserved for "unknown"
             shapes (values of -1 mean "unknown" dimension).  Certain wrappers
             that work with TensorShapeProto may fail at runtime when deserializing
             a TensorShapeProto containing a dim value of -1.
        name:
          type: string
          title: name
          description: Optional name of the tensor dimension.
      title: Dim
      additionalProperties: false
      description: One dimension of the tensor.
    tensorflow.ThreadPoolOptionProto:
      type: object
      properties:
        numThreads:
          type: integer
          title: num_threads
          format: int32
          description: |-
            The number of threads in the pool.

             0 means the system picks a value based on where this option proto is used
             (see the declaration of the specific field for more info).
        globalName:
          type: string
          title: global_name
          description: |-
            The global name of the threadpool.

             If empty, then the threadpool is made and used according to the scope it's
             in - e.g., for a session threadpool, it is used by that session only.

             If non-empty, then:
             - a global threadpool associated with this name is looked
               up or created. This allows, for example, sharing one threadpool across
               many sessions (e.g., like the default behavior, if
               inter_op_parallelism_threads is not configured), but still partitioning
               into a large and small pool.
             - if the threadpool for this global_name already exists, then it is an
               error if the existing pool was created using a different num_threads
               value as is specified on this call.
             - threadpools created this way are never garbage collected.
      title: ThreadPoolOptionProto
      additionalProperties: false
    tensorflow.VariantTensorDataProto:
      type: object
      properties:
        typeName:
          type: string
          title: type_name
          description: Name of the type of objects being serialized.
        metadata:
          type: string
          title: metadata
          format: byte
          description: Portions of the object that are not Tensors.
        tensors:
          type: array
          items:
            $ref: '#/components/schemas/tensorflow.TensorProto'
          title: tensors
          description: Tensors contained within objects being serialized.
      title: VariantTensorDataProto
      additionalProperties: false
      description: Protocol buffer representing the serialization format of DT_VARIANT tensors.
    tensorflow.VerifierConfig:
      type: object
      properties:
        verificationTimeoutInMs:
          oneOf:
            - type: string
            - type: integer
              format: int64
          title: verification_timeout_in_ms
          description: |-
            Deadline for completion of all verification i.e. all the Toggle ON
             verifiers must complete execution within this time.
        structureVerifier:
          allOf:
            - title: structure_verifier
              description: Perform structural validation on a tensorflow graph. Default is OFF.
            - $ref: '#/components/schemas/tensorflow.VerifierConfig.Toggle'
      title: VerifierConfig
      additionalProperties: false
      description: The config for graph verifiers.
    tensorflow.VersionDef:
      type: object
      properties:
        producer:
          type: integer
          title: producer
          format: int32
          description: The version of the code that produced this data.
        minConsumer:
          type: integer
          title: min_consumer
          format: int32
          description: Any consumer below this version is not allowed to consume this data.
        badConsumers:
          type: array
          items:
            type: integer
            format: int32
          title: bad_consumers
          description: Specific consumer versions which are disallowed (e.g. due to bugs).
      title: VersionDef
      additionalProperties: false
      description: |-
        Version information for a piece of serialized data

         There are different types of versions for each type of data
         (GraphDef, etc.), but they all have the same common shape
         described here.

         Each consumer has "consumer" and "min_producer" versions (specified
         elsewhere).  A consumer is allowed to consume this data if

           producer >= min_producer
           consumer >= min_consumer
           consumer not in bad_consumers
    connect-protocol-version:
      type: number
      title: Connect-Protocol-Version
      enum:
        - 1
      description: Define the version of the Connect protocol
      const: 1
    connect-timeout-header:
      type: number
      title: Connect-Timeout-Ms
      description: Define the timeout, in ms
    connect.error:
      type: object
      properties:
        code:
          type: string
          examples:
            - CodeNotFound
          enum:
            - CodeCanceled
            - CodeUnknown
            - CodeInvalidArgument
            - CodeDeadlineExceeded
            - CodeNotFound
            - CodeAlreadyExists
            - CodePermissionDenied
            - CodeResourceExhausted
            - CodeFailedPrecondition
            - CodeAborted
            - CodeOutOfRange
            - CodeInternal
            - CodeUnavailable
            - CodeDataLoss
            - CodeUnauthenticated
          description: The status code, which should be an enum value of [google.rpc.Code][google.rpc.Code].
        message:
          type: string
          description: A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the [google.rpc.Status.details][google.rpc.Status.details] field, or localized by the client.
        detail:
          $ref: '#/components/schemas/google.protobuf.Any'
      title: Connect Error
      additionalProperties: true
      description: 'Error type returned by Connect: https://connectrpc.com/docs/go/errors/#http-representation'
    google.protobuf.Any:
      type: object
      properties:
        type:
          type: string
        value:
          type: string
          format: binary
        debug:
          type: object
          additionalProperties: true
      additionalProperties: true
      description: Contains an arbitrary serialized message along with a @type that describes the type of the serialized message.
security: []
tags:
  - name: tensorflowtest.MasterService
